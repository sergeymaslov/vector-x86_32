---
last_modified_on: "2020-07-13"
$schema: "/.meta/.schemas/guides.json"
title: "Send logs from a file to AWS Kinesis Data Streams"
description: "A simple guide to send logs from a file to AWS Kinesis Data Streams in just a few minutes."
author_github: https://github.com/binarylogic
cover_label: "File to AWS Kinesis Data Streams Integration"
tags: ["type: tutorial","domain: sources","domain: sinks","source: file","sink: aws_kinesis_streams"]
hide_pagination: true
---

import ConfigExample from '@site/src/components/ConfigExample';
import DaemonDiagram from '@site/src/components/DaemonDiagram';
import InstallationCommand from '@site/src/components/InstallationCommand';
import Jump from '@site/src/components/Jump';
import Steps from '@site/src/components/Steps';

Logs are an _essential_ part of observing any
service; without them you are flying blind. But collecting and analyzing them
can be a real challenge -- especially at scale. Not only do you need to solve
the basic task of collecting your logs, but you must do it
in a reliable, performant, and robust manner. Nothing is more frustrating than
having your logs pipeline fall on it's face during an
outage, or even worse, disrupt more important services!

Fear not! In this guide we'll show you how to send send logs from [a file][urls.file] to [AWS Kinesis Data Streams][urls.aws_kinesis_streams]
and build a logs pipeline that will be the backbone of
your observability strategy.

<!--
     THIS FILE IS AUTOGENERATED!

     To make changes please edit the template located at:

     website/guides/integrate/sources/file/aws_kinesis_streams.md.erb
-->

## Background

### What is AWS Kinesis Data Streams?

[Amazon Kinesis Data Streams][urls.aws_kinesis_streams] is a scalable and durable real-time data streaming service that can continuously capture gigabytes of data per second from hundreds of thousands of sources. Making it an excellent candidate for streaming logs and metrics data.

## Strategy

### How This Guide Works

We'll be using [Vector][urls.vector_website] to accomplish this task. Vector
is a [popular][urls.vector_stars] [open-source][urls.vector_repo] utility for
building observability pipelines. It's written in [Rust][urls.rust], making it
lightweight, [ultra-fast][urls.vector_performance] and highly reliable. And
we'll be deploying Vector as a
[daemon][docs.strategies#daemon].

The [daemon deployment strategy][docs.strategies#daemon] is designed for data
collection on a single host. Vector runs in the background, in its own process,
collecting _all_ data for that host.
For this guide, Vector will collect data from
a file via Vector's
[`file`][docs.sources.file].
The following diagram demonstrates how it works.

<DaemonDiagram
  platformName={null}
  sourceName={"file"}
  sinkName={"aws_kinesis_streams"} />

### What We'll Accomplish

To be clear, here's everything we'll accomplish in this short guide:

<ul className="list--icons list--icons--checks list--indent">
  <li>
    Tail one or more files.
    <ul>
      <li>Automatically discover new files with glob patterns.</li>
      <li>Merge multi-line logs into one event.</li>
      <li>Checkpoint your position to ensure data is not lost between restarts.</li>
      <li>Enrich your logs with useful file and host-level context.</li>
    </ul>
  </li>
  <li>
    Send logs to AWS Kinesis Data Streams.
    <ul>
      <li>Batch data to maximize throughput.</li>
      <li>Automatically retry failed requests, with backoff.</li>
      <li>Buffer your data in-memory or on-disk for performance and durability.</li>
    </ul>
  </li>
  <li className="list--icons--arrow text--pink text--bold">All in just a few minutes!</li>
</ul>

## Tutorial

<Steps headingDepth={3}>
<ol>
<li>

### Install Vector

<InstallationCommand />

Or choose your [preferred method][docs.installation].

</li>
<li>

### Configure Vector

<ConfigExample
  format="toml"
  path={"vector.toml"}
  sourceName={"file"}
  sinkName={"aws_kinesis_streams"} />

</li>
<li>

### Start Vector

```bash
vector --config vector.toml
```

That's it! Simple and to the point. Hit `ctrl+c` to exit.

</li>
</ol>
</Steps>

## Next Steps

Vector is _powerful_ utility and we're just scratching the surface in this
guide. Here are a few pages we recommend that demonstrate the power and
flexibility of Vector:

<Jump to="https://github.com/timberio/vector" leftIcon="github" target="_blank">
  <div className="title">Vector Github repo <span className="badge badge--primary"><i className="feather icon-star"></i> 4k</span></div>
  <div className="sub-title">Vector is free and open-source!</div>
</Jump>

<Jump to="/guides/getting-started/" leftIcon="book">
  <div className="title">Vector getting started series</div>
  <div className="sub-title">Go from zero to production in under 10 minutes!</div>
</Jump>

<Jump to="/docs/about/what-is-vector/" leftIcon="book">
  <div className="title">Vector documentation</div>
  <div className="sub-title">Thoughtful, detailed docs that respect your time.</div>
</Jump>

[docs.installation]: /docs/setup/installation/
[docs.sources.file]: /docs/reference/sources/file/
[docs.strategies#daemon]: /docs/setup/deployment/strategies/#daemon
[urls.aws_kinesis_streams]: https://aws.amazon.com/kinesis/data-streams/
[urls.file]: https://en.wikipedia.org/wiki/Computer_file
[urls.rust]: https://www.rust-lang.org/
[urls.vector_performance]: https://vector.dev/#performance
[urls.vector_repo]: https://github.com/timberio/vector
[urls.vector_stars]: https://github.com/timberio/vector/stargazers
[urls.vector_website]: https://vector.dev
