#                                    __   __  __
#                                    \ \ / / / /
#                                     \ V / / /
#                                      \_/  \/
#
#                                    V E C T O R
#                            Configuration Specification
#
# ------------------------------------------------------------------------------
# Website: https://vector.dev
# Docs: https://vector.dev/docs/
# Community: https://vector.dev/community/
# ------------------------------------------------------------------------------
# The file contains a full specification for the `vector.toml` configuration
# file. It follows the TOML format and includes all options, types, and
# possible values.
#
# More info on Vector's configuration can be found at:
# /docs/setup/configuration/

# ------------------------------------------------------------------------------
# Global
# ------------------------------------------------------------------------------
# Global options are relevant to Vector as a whole and apply to global behavior.

#
# General
#

# The directory used for persisting Vector state, such as on-disk buffers, file
# checkpoints, and more. Please make sure the Vector project has write
# permissions to this dir.
#
# * optional
# * default: "/var/lib/vector/"
# * type: string
data_dir = "/var/lib/vector"
data_dir = "/var/local/lib/vector/"
data_dir = "/home/user/vector/"

#
# Log schema
#

[.log_schema]
  # The key used to hold the log host. See the log data model page for more info.
  #
  # * optional
  # * default: "host"
  # * type: string
  host_key = "host"
  host_key = "@host"
  host_key = "instance"
  host_key = "machine"

  # The key used to hold the log message. See the log data model page for more
  # info.
  #
  # * optional
  # * default: "message"
  # * type: string
  message_key = "message"
  message_key = "@message"
  message_key = "msg"

  # The key used to hold the log source type. See the log data model page for
  # more info.
  #
  # * optional
  # * default: "source_type"
  # * type: string
  source_type_key = "source_type"
  source_type_key = "@source_type"
  source_type_key = "src_ty"

  # The key used to represent when the log was generated. See the log data model
  # page for more info.
  #
  # * optional
  # * default: "timestamp"
  # * type: string
  timestamp_key = "timestamp"
  timestamp_key = "@timestamp"
  timestamp_key = "datetime"

# ------------------------------------------------------------------------------
# Sources
# ------------------------------------------------------------------------------
# Sources specify data sources and are responsible for ingesting data into
# Vector.

# Ingests data through the Docker engine daemon and outputs `log` events.
[sources.docker]
  # Setting this to `false` will disable the automatic merging of partial events.
  #
  # * optional
  # * default: true
  # * type: bool
  auto_partial_merge = true
  auto_partial_merge = false

  # A list of container IDs _or_ names to match against. Prefix matches are
  # supported, meaning you can supply just the first few characters of the
  # container ID or name. If not provided, all containers will be included.
  #
  # * optional
  # * no default
  # * type: [string]
  include_containers = ["serene_", "serene_leakey", "ad08cc418cf9"]

  # A list of image names to match against. If not provided, all images will be
  # included.
  #
  # * optional
  # * no default
  # * type: [string]
  include_images = ["httpd", "redis"]

  # A list of container object labels to match against when filtering running
  # containers. This should follow the described label's synatx in docker object
  # labels docs.
  #
  # * optional
  # * no default
  # * type: [string]
  include_labels = ["com.example.vendor=Timber Inc.", "com.example.name=Vector"]

  # The field name to be added to events that are detected to contain an
  # incomplete message (i.e. partial events). If set to `""`, no field will be
  # added to partial event. This allows to opt-out of partial event detection.
  #
  # * optional
  # * default: "_partial"
  # * type: string
  partial_event_marker_field = "_partial"

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "docker"
  type = "docker"

# Ingests data through one or more local files and outputs `log` events.
[sources.file]
  #
  # General
  #

  # The directory used to persist file checkpoint positions. By default, the
  # global `data_dir` option is used. Please make sure the Vector project has
  # write permissions to this dir.
  #
  # * optional
  # * no default
  # * type: string
  data_dir = "/var/lib/vector"

  # Array of file patterns to exclude. Globbing is supported.*Takes precedence
  # over the `include` option.*
  #
  # * optional
  # * no default
  # * type: [string]
  exclude = ["/var/log/nginx/*.[0-9]*.log"]

  # Delay between file discovery calls. This controls the interval at which
  # Vector searches for files.
  #
  # * optional
  # * default: 1000
  # * type: uint
  # * unit: milliseconds
  glob_minimum_cooldown = 1000

  # Ignore files with a data modification date that does not exceed this age.
  #
  # * optional
  # * no default
  # * type: uint
  # * unit: seconds
  ignore_older = 86400

  # Array of file patterns to include. Globbing is supported.
  #
  # * required
  # * type: [string]
  include = ["/var/log/nginx/*.log"]

  # The maximum number of a bytes a line can contain before being discarded. This
  # protects against malformed lines or tailing incorrect files.
  #
  # * optional
  # * default: 102400
  # * type: uint
  # * unit: bytes
  max_line_bytes = 102400

  # Timeout from reaching `eof` after which file will be removed from filesystem,
  # unless new data is written in the meantime. If not specified, files will not
  # be removed.
  #
  # * optional
  # * no default
  # * type: uint
  # * unit: seconds
  remove_after = 0
  remove_after = 5
  remove_after = 60

  # For files with a stored checkpoint at startup, setting this option to `true`
  # will tell Vector to read from the beginning of the file instead of the stored
  # checkpoint.
  #
  # * optional
  # * default: false
  # * type: bool
  start_at_beginning = false
  start_at_beginning = true

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "file"
  type = "file"

  #
  # Context
  #

  # The key name added to each event with the full path of the file.
  #
  # * optional
  # * default: "file"
  # * type: string
  file_key = "file"

  # The key name added to each event representing the current host. This can also
  # be globally set via the global `host_key` option.
  #
  # * optional
  # * default: "host"
  # * type: string
  host_key = "host"

  #
  # Fingerprinting
  #

  [sources.file.fingerprinting]
    # The number of bytes read off the head of the file to generate a unique
    # fingerprint.
    #
    # * optional
    # * default: 256
    # * type: uint
    # * unit: bytes
    # * relevant when strategy = "checksum"
    fingerprint_bytes = 256

    # The number of bytes to skip ahead (or ignore) when generating a unique
    # fingerprint. This is helpful if all files share a common header.
    #
    # * optional
    # * default: 0
    # * type: uint
    # * unit: bytes
    # * relevant when strategy = "checksum"
    ignored_header_bytes = 0

    # The strategy used to uniquely identify files. This is important for
    # checkpointing when file rotation is used.
    #
    # * optional
    # * default: "checksum"
    # * type: string
    # * enum: "checksum" or "device_and_inode"
    strategy = "checksum"
    strategy = "device_and_inode"

  #
  # Priority
  #

  # An approximate limit on the amount of data read from a single file at a given
  # time.
  #
  # * optional
  # * default: 2048
  # * type: uint
  # * unit: bytes
  max_read_bytes = 2048

  # Instead of balancing read capacity fairly across all watched files,
  # prioritize draining the oldest files before moving on to read data from
  # younger files.
  #
  # * optional
  # * default: false
  # * type: bool
  oldest_first = false
  oldest_first = true

  #
  # Multiline
  #

  [sources.file.multiline]
    # Condition regex pattern to look for. Exact behavior is configured via `mode`.
    #
    # * required
    # * type: string
    condition_pattern = "^[\\s]+"
    condition_pattern = "\\\\$"
    condition_pattern = "^(INFO|ERROR) "
    condition_pattern = ";$"

    # Mode of operation, specifies how the `condition_pattern` is interpreted.
    #
    # * required
    # * type: string
    # * enum: "continue_through", "continue_past", "halt_before", and "halt_with"
    mode = "continue_through"
    mode = "continue_past"
    mode = "halt_before"
    mode = "halt_with"

    # Start regex pattern to look for as a beginning of the message.
    #
    # * required
    # * type: string
    start_pattern = "^[^\\s]"
    start_pattern = "\\\\$"
    start_pattern = "^(INFO|ERROR) "
    start_pattern = "[^;]$"

    # The maximum time to wait for the continuation. Once this timeout is reached,
    # the buffered message is guaraneed to be flushed, even if incomplete.
    #
    # * required
    # * type: uint
    # * unit: milliseconds
    timeout_ms = 1000
    timeout_ms = 600000

# Ingests data through an internal data generator and outputs `log` events.
[sources.generator]
  # The amount of time, in seconds, to pause between each batch of output lines.
  # If not set, there will be no delay.
  #
  # * optional
  # * no default
  # * type: float
  batch_interval = 1.0

  # The number of times to repeat outputting the `lines`.
  #
  # * optional
  # * default: "infinite"
  # * type: uint
  count = "infinite"

  # The list of lines to output.
  #
  # * required
  # * type: [string]
  lines = ["Line 1", "Line 2"]

  # If `true`, each output line will start with an increasing sequence number.
  #
  # * optional
  # * default: false
  # * type: bool
  sequence = false
  sequence = true

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "generator"
  type = "generator"

# Ingests data through the HTTP protocol and outputs `log` events.
[sources.http]
  #
  # General
  #

  # The address to listen for connections on
  #
  # * required
  # * type: string
  address = "0.0.0.0:80"
  address = "localhost:80"

  # The expected encoding of received data. Note that for `json` and `ndjson`
  # encodings, the fields of the JSON objects are output as separate fields.
  #
  # * optional
  # * default: "text"
  # * type: string
  # * enum: "text", "ndjson", and "json"
  encoding = "text"
  encoding = "ndjson"
  encoding = "json"

  # A list of HTTP headers to include in the log event. These will override any
  # values included in the JSON payload with conflicting names. An empty string
  # will be inserted into the log event if the corresponding HTTP header was
  # missing.
  #
  # * optional
  # * no default
  # * type: [string]
  headers = ["User-Agent", "X-My-Custom-Header"]

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "http"
  type = "http"

  #
  # TLS
  #

  [sources.http.tls]
    # Absolute path to an additional CA certificate file, in DER or PEM format
    # (X.509), or an inline CA certificate in PEM format.
    #
    # * optional
    # * no default
    # * type: string
    ca_file = "/path/to/certificate_authority.crt"

    # Absolute path to a certificate file used to identify this server, in DER or
    # PEM format (X.509) or PKCS#12, or an inline certificate in PEM format. If
    # this is set and is not a PKCS#12 archive, `key_file` must also be set. This
    # is required if `enabled` is set to `true`.
    #
    # * optional
    # * no default
    # * type: string
    crt_file = "/path/to/host_certificate.crt"

    # Require TLS for incoming connections. If this is set, an identity certificate
    # is also required.
    #
    # * optional
    # * default: false
    # * type: bool
    enabled = false
    enabled = true

    # Absolute path to a private key file used to identify this server, in DER or
    # PEM format (PKCS#8), or an inline private key in PEM format.
    #
    # * optional
    # * no default
    # * type: string
    key_file = "/path/to/host_certificate.key"

    # Pass phrase used to unlock the encrypted key file. This has no effect unless
    # `key_file` is set.
    #
    # * optional
    # * no default
    # * type: string
    key_pass = "${KEY_PASS_ENV_VAR}"
    key_pass = "PassWord1"

    # If `true`, Vector will require a TLS certificate from the connecting host and
    # terminate the connection if it is not valid. If `false` (the default), Vector
    #  will not request a certificate from the client.
    #
    # * optional
    # * default: false
    # * type: bool
    verify_certificate = false
    verify_certificate = true

# Ingests data through Systemd's Journald utility and outputs `log` events.
[sources.journald]
  # The systemd journal is read in batches, and a checkpoint is set at the end of
  # each batch. This option limits the size of the batch.
  #
  # * optional
  # * default: 16
  # * type: uint
  batch_size = 16

  # Include only entries from the current boot.
  #
  # * optional
  # * default: true
  # * type: bool
  current_boot_only = true
  current_boot_only = false

  # The directory used to persist the journal checkpoint position. By default,
  # the global `data_dir` is used. Please make sure the Vector project has write
  # permissions to this dir.
  #
  # * optional
  # * no default
  # * type: string
  data_dir = "/var/lib/vector"

  # The list of units names to exclude from monitoring. Unit names lacking a
  # `"."` will have `".service"` appended to make them a valid service unit name.
  #
  # * optional
  # * default: []
  # * type: [string]
  exclude_units = ["badservice", "sysinit.target"]

  # The list of units names to monitor. If empty or not present, all units are
  # accepted. Unit names lacking a `"."` will have `".service"` appended to make
  # them a valid service unit name.
  #
  # * optional
  # * default: []
  # * type: [string]
  include_units = ["ntpd", "sysinit.target"]

  # The full path of the `journalctl` executable. If not set, Vector will search
  # the path for `journalctl`.
  #
  # * optional
  # * default: "journalctl"
  # * type: string
  journalctl_path = "/usr/local/bin/journalctl"

  # If the record from journald contains a `PRIORITY` field, it will be remapped
  # into the equivalent syslog priority level name using the standard
  # (abbreviated) all-capitals names such as `EMERG` or `ERR`.
  #
  # * optional
  # * default: false
  # * type: bool
  remap_priority = false
  remap_priority = true

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "journald"
  type = "journald"

# Ingests data through Kafka and outputs `log` events.
[sources.kafka]
  #
  # General
  #

  # If offsets for consumer group do not exist, set them using this strategy.
  # librdkafka documentation for `auto.offset.reset` option for explanation.
  #
  # * optional
  # * default: "largest"
  # * type: string
  auto_offset_reset = "smallest"
  auto_offset_reset = "earliest"
  auto_offset_reset = "beginning"
  auto_offset_reset = "largest"
  auto_offset_reset = "latest"
  auto_offset_reset = "end"
  auto_offset_reset = "error"

  # A comma-separated list of host and port pairs that are the addresses of the
  # Kafka brokers in a "bootstrap" Kafka cluster that a Kafka client connects to
  # initially to bootstrap itself.
  #
  # * required
  # * type: string
  bootstrap_servers = "10.14.22.123:9092,10.14.23.332:9092"

  # The frequency that the consumer offsets are committed (written) to offset
  # storage.
  #
  # * optional
  # * default: 5000
  # * type: uint
  # * unit: milliseconds
  commit_interval_ms = 5000
  commit_interval_ms = 10000

  # Maximum time the broker may wait to fill the response.
  #
  # * optional
  # * default: 100
  # * type: uint
  # * unit: milliseconds
  fetch_wait_max_ms = 50
  fetch_wait_max_ms = 100

  # The consumer group name to be used to consume events from Kafka.
  #
  # * required
  # * type: string
  group_id = "consumer-group-name"

  # The log field name to use for the Kafka message key. If unspecified, the key
  # would not be added to the log event. If the message has null key, then this
  # field would not be added to the log event.
  #
  # * optional
  # * no default
  # * type: string
  key_field = "message_key"

  # The Kafka session timeout in milliseconds.
  #
  # * optional
  # * default: 10000
  # * type: uint
  # * unit: milliseconds
  session_timeout_ms = 5000
  session_timeout_ms = 10000

  # Default timeout for network requests.
  #
  # * optional
  # * default: 60000
  # * type: uint
  # * unit: milliseconds
  socket_timeout_ms = 30000
  socket_timeout_ms = 60000

  # The Kafka topics names to read events from. Regex is supported if the topic
  # begins with `^`.
  #
  # * required
  # * type: [string]
  topics = ["^(prefix1|prefix2)-.+", "topic-1", "topic-2"]

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "kafka"
  type = "kafka"

  #
  # Advanced
  #

  [sources.kafka.librdkafka_options]
    # The options and their values. Accepts `string` values.
    #
    # * optional
    # * no default
    # * type: string
    "client.id" = "${ENV_VAR}"
    "fetch.error.backoff.ms" = "1000"
    "socket.send.buffer.bytes" = "100"

  #
  # SASL
  #

  [sources.kafka.sasl]
    # Enable SASL/SCRAM authentication to the remote. (Not supported on Windows at
    # this time.)
    #
    # * optional
    # * no default
    # * type: bool
    enabled = true
    enabled = false

    # The Kafka SASL/SCRAM mechanisms.
    #
    # * optional
    # * no default
    # * type: string
    mechanism = "SCRAM-SHA-256"
    mechanism = "SCRAM-SHA-512"

    # The Kafka SASL/SCRAM authentication password.
    #
    # * optional
    # * no default
    # * type: string
    password = "password"

    # The Kafka SASL/SCRAM authentication username.
    #
    # * optional
    # * no default
    # * type: string
    username = "username"

  #
  # TLS
  #

  [sources.kafka.tls]
    # Absolute path to an additional CA certificate file, in DER or PEM format
    # (X.509), or an inline CA certificate in PEM format.
    #
    # * optional
    # * no default
    # * type: string
    ca_file = "/path/to/certificate_authority.crt"

    # Absolute path to a certificate file used to identify this connection, in DER
    # or PEM format (X.509) or PKCS#12, or an inline certificate in PEM format. If
    # this is set and is not a PKCS#12 archive, `key_file` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    crt_file = "/path/to/host_certificate.crt"

    # Enable TLS during connections to the remote.
    #
    # * optional
    # * default: false
    # * type: bool
    enabled = false
    enabled = true

    # Absolute path to a private key file used to identify this connection, in DER
    # or PEM format (PKCS#8), or an inline private key in PEM format. If this is
    # set, `crt_file` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    key_file = "/path/to/host_certificate.key"

    # Pass phrase used to unlock the encrypted key file. This has no effect unless
    # `key_file` is set.
    #
    # * optional
    # * no default
    # * type: string
    key_pass = "${KEY_PASS_ENV_VAR}"
    key_pass = "PassWord1"

# Ingests data through the Heroku Logplex HTTP Drain protocol and outputs `log` events.
[sources.logplex]
  #
  # General
  #

  # The address to accept connections on. The address _must_ include a port.
  #
  # * required
  # * type: string
  address = "0.0.0.0:80"

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "logplex"
  type = "logplex"

  #
  # TLS
  #

  [sources.logplex.tls]
    # Absolute path to an additional CA certificate file, in DER or PEM format
    # (X.509), or an inline CA certificate in PEM format.
    #
    # * optional
    # * no default
    # * type: string
    ca_file = "/path/to/certificate_authority.crt"

    # Absolute path to a certificate file used to identify this server, in DER or
    # PEM format (X.509) or PKCS#12, or an inline certificate in PEM format. If
    # this is set and is not a PKCS#12 archive, `key_file` must also be set. This
    # is required if `enabled` is set to `true`.
    #
    # * optional
    # * no default
    # * type: string
    crt_file = "/path/to/host_certificate.crt"

    # Require TLS for incoming connections. If this is set, an identity certificate
    # is also required.
    #
    # * optional
    # * default: false
    # * type: bool
    enabled = false
    enabled = true

    # Absolute path to a private key file used to identify this server, in DER or
    # PEM format (PKCS#8), or an inline private key in PEM format.
    #
    # * optional
    # * no default
    # * type: string
    key_file = "/path/to/host_certificate.key"

    # Pass phrase used to unlock the encrypted key file. This has no effect unless
    # `key_file` is set.
    #
    # * optional
    # * no default
    # * type: string
    key_pass = "${KEY_PASS_ENV_VAR}"
    key_pass = "PassWord1"

    # If `true`, Vector will require a TLS certificate from the connecting host and
    # terminate the connection if it is not valid. If `false` (the default), Vector
    #  will not request a certificate from the client.
    #
    # * optional
    # * default: false
    # * type: bool
    verify_certificate = false
    verify_certificate = true

# Ingests data through the Prometheus text exposition format and outputs `metric` events.
[sources.prometheus]
  # Host addresses to scrape metrics from.
  #
  # * required
  # * type: [string]
  hosts = ["http://localhost:9090"]

  # The interval between scrapes, in seconds.
  #
  # * optional
  # * default: 15
  # * type: uint
  # * unit: seconds
  scrape_interval_secs = 15

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "prometheus"
  type = "prometheus"

# Ingests data through a socket, such as a TCP, UDP, or UDS socket and outputs `log` events.
[sources.socket]
  #
  # General
  #

  # The address to listen for connections on, or `systemd#N` to use the Nth
  # socket passed by systemd socket activation. If an address is used it _must_
  # include a port.
  #
  # * required
  # * type: string
  # * required when mode = "tcp" or mode = "udp"
  address = "0.0.0.0:9000"
  address = "systemd"
  address = "systemd#3"

  # The maximum bytes size of incoming messages before they are discarded.
  #
  # * optional
  # * default: 102400
  # * type: uint
  # * unit: bytes
  # * relevant when mode = "tcp" or mode = "unix"
  max_length = 102400

  # The type of socket to use.
  #
  # * required
  # * type: string
  # * enum: "tcp", "udp", and "unix"
  mode = "tcp"
  mode = "udp"
  mode = "unix"

  # The unix socket path. *This should be absolute path*.
  #
  # * required
  # * type: string
  # * required when mode = "unix"
  path = "/path/to/socket"

  # The timeout before a connection is forcefully closed during shutdown.
  #
  # * optional
  # * default: 30
  # * type: uint
  # * unit: seconds
  # * relevant when mode = "tcp"
  shutdown_timeout_secs = 30

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "socket"
  type = "socket"

  #
  # Context
  #

  # The key name added to each event representing the current host. This can also
  # be globally set via the global `host_key` option.
  #
  # * optional
  # * default: "host"
  # * type: string
  host_key = "host"

  #
  # TLS
  #

  [sources.socket.tls]
    # Absolute path to an additional CA certificate file, in DER or PEM format
    # (X.509), or an inline CA certificate in PEM format.
    #
    # * optional
    # * no default
    # * type: string
    # * relevant when mode = "tcp"
    ca_file = "/path/to/certificate_authority.crt"

    # Absolute path to a certificate file used to identify this server, in DER or
    # PEM format (X.509) or PKCS#12, or an inline certificate in PEM format. If
    # this is set and is not a PKCS#12 archive, `key_file` must also be set. This
    # is required if `enabled` is set to `true`.
    #
    # * optional
    # * no default
    # * type: string
    # * relevant when mode = "tcp"
    crt_file = "/path/to/host_certificate.crt"

    # Require TLS for incoming connections. If this is set, an identity certificate
    # is also required.
    #
    # * optional
    # * default: false
    # * type: bool
    # * relevant when mode = "tcp"
    enabled = false
    enabled = true

    # Absolute path to a private key file used to identify this server, in DER or
    # PEM format (PKCS#8), or an inline private key in PEM format.
    #
    # * optional
    # * no default
    # * type: string
    # * relevant when mode = "tcp"
    key_file = "/path/to/host_certificate.key"

    # Pass phrase used to unlock the encrypted key file. This has no effect unless
    # `key_file` is set.
    #
    # * optional
    # * no default
    # * type: string
    # * relevant when mode = "tcp"
    key_pass = "${KEY_PASS_ENV_VAR}"
    key_pass = "PassWord1"

    # If `true`, Vector will require a TLS certificate from the connecting host and
    # terminate the connection if it is not valid. If `false` (the default), Vector
    #  will not request a certificate from the client.
    #
    # * optional
    # * default: false
    # * type: bool
    # * relevant when mode = "tcp"
    verify_certificate = false
    verify_certificate = true

# Ingests data through the Splunk HTTP Event Collector protocol and outputs `log` events.
[sources.splunk_hec]
  #
  # General
  #

  # The address to accept connections on.
  #
  # * optional
  # * default: "0.0.0.0:80"
  # * type: string
  address = "0.0.0.0:80"

  # If supplied, incoming requests must supply this token in the `Authorization`
  # header, just as a client would if it was communicating with the Splunk HEC
  # endpoint directly. If _not_ supplied, the `Authorization` header will be
  # ignored and requests will not be authenticated.
  #
  # * optional
  # * no default
  # * type: string
  token = "A94A8FE5CCB19BA61C4C08"

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "splunk_hec"
  type = "splunk_hec"

  #
  # TLS
  #

  [sources.splunk_hec.tls]
    # Absolute path to an additional CA certificate file, in DER or PEM format
    # (X.509), or an inline CA certificate in PEM format.
    #
    # * optional
    # * no default
    # * type: string
    ca_file = "/path/to/certificate_authority.crt"

    # Absolute path to a certificate file used to identify this server, in DER or
    # PEM format (X.509) or PKCS#12, or an inline certificate in PEM format. If
    # this is set and is not a PKCS#12 archive, `key_file` must also be set. This
    # is required if `enabled` is set to `true`.
    #
    # * optional
    # * no default
    # * type: string
    crt_file = "/path/to/host_certificate.crt"

    # Require TLS for incoming connections. If this is set, an identity certificate
    # is also required.
    #
    # * optional
    # * default: false
    # * type: bool
    enabled = false
    enabled = true

    # Absolute path to a private key file used to identify this server, in DER or
    # PEM format (PKCS#8), or an inline private key in PEM format.
    #
    # * optional
    # * no default
    # * type: string
    key_file = "/path/to/host_certificate.key"

    # Pass phrase used to unlock the encrypted key file. This has no effect unless
    # `key_file` is set.
    #
    # * optional
    # * no default
    # * type: string
    key_pass = "${KEY_PASS_ENV_VAR}"
    key_pass = "PassWord1"

    # If `true`, Vector will require a TLS certificate from the connecting host and
    # terminate the connection if it is not valid. If `false` (the default), Vector
    #  will not request a certificate from the client.
    #
    # * optional
    # * default: false
    # * type: bool
    verify_certificate = false
    verify_certificate = true

# Ingests data through the StatsD UDP protocol and outputs `metric` events.
[sources.statsd]
  # UDP socket address to bind to.
  #
  # * required
  # * type: string
  address = "127.0.0.1:8126"

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "statsd"
  type = "statsd"

# Ingests data through standard input (STDIN) and outputs `log` events.
[sources.stdin]
  #
  # Context
  #

  # The key name added to each event representing the current host. This can also
  # be globally set via the global `host_key` option.
  #
  # * optional
  # * default: "host"
  # * type: string
  host_key = "host"

  #
  # General
  #

  # The maxiumum bytes size of a message before it is discarded.
  #
  # * optional
  # * default: 102400
  # * type: uint
  # * unit: bytes
  max_length = 102400

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "stdin"
  type = "stdin"

# Ingests data through the Syslog protocol and outputs `log` events.
[sources.syslog]
  #
  # General
  #

  # The TCP or UDP address to listen for connections on, or "systemd#N" to use
  # the Nth socket passed by systemd socket activation.
  #
  # * required
  # * type: string
  # * required when mode = "tcp" or mode = "udp"
  address = "0.0.0.0:514"
  address = "systemd"
  address = "systemd#2"

  # The maximum bytes size of incoming messages before they are discarded.
  #
  # * optional
  # * default: 102400
  # * type: uint
  # * unit: bytes
  max_length = 102400

  # The input mode.
  #
  # * required
  # * type: string
  # * enum: "tcp", "udp", and "unix"
  mode = "tcp"
  mode = "udp"
  mode = "unix"

  # The unix socket path. *This should be absolute path.*
  #
  # * required
  # * type: string
  # * required when mode = "unix"
  path = "/path/to/socket"

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "syslog"
  type = "syslog"

  #
  # Context
  #

  # The key name added to each event representing the current host. This can also
  # be globally set via the global `host_key` option.
  #
  # * optional
  # * default: "host"
  # * type: string
  host_key = "host"

  #
  # TLS
  #

  [sources.syslog.tls]
    # Absolute path to an additional CA certificate file, in DER or PEM format
    # (X.509), or an inline CA certificate in PEM format.
    #
    # * optional
    # * no default
    # * type: string
    ca_file = "/path/to/certificate_authority.crt"

    # Absolute path to a certificate file used to identify this server, in DER or
    # PEM format (X.509) or PKCS#12, or an inline certificate in PEM format. If
    # this is set and is not a PKCS#12 archive, `key_file` must also be set. This
    # is required if `enabled` is set to `true`.
    #
    # * optional
    # * no default
    # * type: string
    crt_file = "/path/to/host_certificate.crt"

    # Require TLS for incoming connections. If this is set, an identity certificate
    # is also required.
    #
    # * optional
    # * default: false
    # * type: bool
    enabled = false
    enabled = true

    # Absolute path to a private key file used to identify this server, in DER or
    # PEM format (PKCS#8), or an inline private key in PEM format.
    #
    # * optional
    # * no default
    # * type: string
    key_file = "/path/to/host_certificate.key"

    # Pass phrase used to unlock the encrypted key file. This has no effect unless
    # `key_file` is set.
    #
    # * optional
    # * no default
    # * type: string
    key_pass = "${KEY_PASS_ENV_VAR}"
    key_pass = "PassWord1"

    # If `true`, Vector will require a TLS certificate from the connecting host and
    # terminate the connection if it is not valid. If `false` (the default), Vector
    #  will not request a certificate from the client.
    #
    # * optional
    # * default: false
    # * type: bool
    verify_certificate = false
    verify_certificate = true

# Ingests data through another upstream `vector` sink and outputs `log` and `metric` events.
[sources.vector]
  #
  # General
  #

  # The TCP address to listen for connections on, or `systemd#N to use the Nth
  # socket passed by systemd socket activation. If an address is used it _must_
  # include a port.
  #
  # * required
  # * type: string
  address = "0.0.0.0:9000"
  address = "systemd"
  address = "systemd#1"

  # The timeout before a connection is forcefully closed during shutdown.
  #
  # * optional
  # * default: 30
  # * type: uint
  # * unit: seconds
  shutdown_timeout_secs = 30

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "vector"
  type = "vector"

  #
  # TLS
  #

  [sources.vector.tls]
    # Absolute path to an additional CA certificate file, in DER or PEM format
    # (X.509), or an inline CA certificate in PEM format.
    #
    # * optional
    # * no default
    # * type: string
    ca_file = "/path/to/certificate_authority.crt"

    # Absolute path to a certificate file used to identify this server, in DER or
    # PEM format (X.509) or PKCS#12, or an inline certificate in PEM format. If
    # this is set and is not a PKCS#12 archive, `key_file` must also be set. This
    # is required if `enabled` is set to `true`.
    #
    # * optional
    # * no default
    # * type: string
    crt_file = "/path/to/host_certificate.crt"

    # Require TLS for incoming connections. If this is set, an identity certificate
    # is also required.
    #
    # * optional
    # * default: false
    # * type: bool
    enabled = false
    enabled = true

    # Absolute path to a private key file used to identify this server, in DER or
    # PEM format (PKCS#8), or an inline private key in PEM format.
    #
    # * optional
    # * no default
    # * type: string
    key_file = "/path/to/host_certificate.key"

    # Pass phrase used to unlock the encrypted key file. This has no effect unless
    # `key_file` is set.
    #
    # * optional
    # * no default
    # * type: string
    key_pass = "${KEY_PASS_ENV_VAR}"
    key_pass = "PassWord1"

    # If `true`, Vector will require a TLS certificate from the connecting host and
    # terminate the connection if it is not valid. If `false` (the default), Vector
    #  will not request a certificate from the client.
    #
    # * optional
    # * default: false
    # * type: bool
    verify_certificate = false
    verify_certificate = true


# ------------------------------------------------------------------------------
# Transforms
# ------------------------------------------------------------------------------
# Transforms parse, structure, and enrich events.

# Accepts and outputs `log` events, allowing you to add one or more log fields.
[transforms.add_fields]
  #
  # Fields
  #

  [transforms.add_fields.fields]
    # The name of the field to add. Accepts all supported types. Use `.` for adding
    # nested fields.
    #
    # * required
    # * type: *
    string_field = "string value"
    env_var_field = "${ENV_VAR}"
    templated_field = "{{ my_other_field }}"
    int_field = 1
    float_field = 1.2
    bool_field = true
    timestamp_field = 1979-05-27T00:32:00Z
    parent = {child_field = "child_value"}
    list_field = ["first", "second", "third"]

  #
  # General
  #

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # By default, fields will be overridden. Set this to `false` to avoid
  # overwriting values.
  #
  # * optional
  # * default: true
  # * type: bool
  overwrite = true
  overwrite = false

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "add_fields"
  type = "add_fields"

# Accepts and outputs `metric` events, allowing you to add one or more metric tags.
[transforms.add_tags]
  #
  # General
  #

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # By default, fields will be overridden. Set this to `false` to avoid
  # overwriting values.
  #
  # * optional
  # * default: true
  # * type: bool
  overwrite = true
  overwrite = false

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "add_tags"
  type = "add_tags"

  #
  # Tags
  #

  [transforms.add_tags.tags]
    # The name of the tag to add. Due to the nature of metric tags, the value must
    # be a string.
    #
    # * required
    # * type: string
    static_tag = "my value"
    env_tag = "${ENV_VAR}"

# Accepts and outputs `log` events, allowing you to strips ANSI escape sequences from the specified field.
[transforms.ansi_stripper]
  # The target field to strip ANSI escape sequences from.
  #
  # * optional
  # * default: "message"
  # * type: string
  field = "message"
  field = "parent.child"
  field = "array[0]"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "ansi_stripper"
  type = "ansi_stripper"

# Accepts and outputs `log` events, allowing you to enrich logs with AWS EC2 instance metadata.
[transforms.aws_ec2_metadata]
  # A list of fields to include in each event.
  #
  # * optional
  # * default: ["instance-id", "local-hostname", "local-ipv4", "public-hostname", "public-ipv4", "ami-id", "availability-zone", "vpc-id", "subnet-id", "region"]
  # * type: [string]
  fields = ["instance-id", "local-hostname", "local-ipv4", "public-hostname", "public-ipv4", "ami-id", "availability-zone", "vpc-id", "subnet-id", "region"]

  # Override the default EC2 Metadata host.
  #
  # * optional
  # * default: "http://169.254.169.254"
  # * type: string
  host = "http://169.254.169.254"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # Prepend a namespace to each field's key.
  #
  # * optional
  # * default: ""
  # * type: string
  namespace = ""
  namespace = "ec2"
  namespace = "aws.ec2"

  # The interval in seconds at which the EC2 Metadata api will be called.
  #
  # * optional
  # * default: 10
  # * type: uint
  refresh_interval_secs = 10

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "aws_ec2_metadata"
  type = "aws_ec2_metadata"

# Accepts and outputs `log` events, allowing you to coerce log fields into fixed types.
[transforms.coercer]
  #
  # General
  #

  # Set to `true` to drop all fields that are not specified in the `types` table.
  # Make sure both `message` and `timestamp` are specified in the `types` table
  # as their absense will cause the original message data to be dropped along
  # with other extraneous fields.
  #
  # * optional
  # * default: false
  # * type: bool
  drop_unspecified = false
  drop_unspecified = true

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "coercer"
  type = "coercer"

  #
  # Types
  #

  [transforms.coercer.types]
    # A definition of log field type conversions. They key is the log field name
    # and the value is the type. `strptime` specifiers are supported for the
    # `timestamp` type.
    #
    # * optional
    # * no default
    # * type: string
    # * enum: "bool", "float", "int", "string", and "timestamp"
    status = "int"
    duration = "float"
    success = "bool"
    timestamp = "timestamp|%F"
    timestamp = "timestamp|%a %b %e %T %Y"
    parent = {child = "int"}

# Accepts and outputs `log` events, allowing you to concat (substrings) of other fields to a new one.
[transforms.concat]
  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # A list of substring definitons in the format of source_field[start..end]. For
  # both start and end negative values are counted from the end of the string.
  #
  # * required
  # * type: [string]
  items = ["first[..3]", "second[-5..]", "third[3..6]"]

  # The string that is used to join all items.
  #
  # * optional
  # * default: " "
  # * type: string
  joiner = " "
  joiner = ","
  joiner = "_"
  joiner = "+"

  # The name for the new label.
  #
  # * required
  # * type: string
  target = "root_field_name"
  target = "parent.child"
  target = "array[0]"

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "concat"
  type = "concat"

# Accepts and outputs `log` events, allowing you to prevent duplicate Events from being outputted by using an LRU cache.
[transforms.dedupe]
  #
  # Cache
  #

  [transforms.dedupe.cache]
    # The number of recent Events to cache and compare new incoming Events against.
    #
    # * optional
    # * default: 5000
    # * type: uint
    num_events = 5000

  #
  # Fields
  #

  [transforms.dedupe.fields]
    # The field names to ignore when deciding if an Event is a duplicate.
    # Incompatible with the `fields.match` option.
    #
    # * optional
    # * no default
    # * type: [string]
    ignore = ["field1", "parent.child_field"]

    # The field names considered when deciding if an Event is a duplicate. This can
    # also be globally set via the global `log_schema` options.Incompatible with
    # the `fields.ignore` option.
    #
    # * optional
    # * default: ["timestamp", "host", "message"]
    # * type: [string]
    match = ["field1", "parent.child_field"]

  #
  # General
  #

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "dedupe"
  type = "dedupe"

# Accepts and outputs `log` and `metric` events, allowing you to select events based on a set of logical conditions.
[transforms.filter]
  #
  # Condition
  #

  [transforms.filter.condition]
    # The type of the condition to execute.
    #
    # * optional
    # * default: "check_fields"
    # * type: string
    # * enum: "check_fields", "is_log", and "is_metric"
    type = "check_fields"
    type = "is_log"
    type = "is_metric"

    # Check whether a fields contents exactly matches the value specified. This may
    # be a single string or a list of strings, in which case this evaluates to true
    # if any of the list matches.
    #
    # * optional
    # * no default
    # * type: string
    # * relevant when type = "check_fields"
    "message.eq" = "this is the content to match against"
    "message.eq" = ["match this", "or this"]

    # Check whether a field exists or does not exist, depending on the provided
    # value being `true` or `false` respectively.
    #
    # * optional
    # * no default
    # * type: bool
    # * relevant when type = "check_fields"
    "host.exists" = true

    # Check whether a fields contents does not match the value specified. This may
    # be a single string or a list of strings, in which case this evaluates to
    # false if any of the list matches.
    #
    # * optional
    # * no default
    # * type: string
    # * relevant when type = "check_fields"
    "method.neq" = "POST"
    "method.neq" = ["POST", "GET"]

    # Check if the given `[condition]` does not match.
    #
    # * optional
    # * no default
    # * type: any
    # * relevant when type = "check_fields"
    "message.not_contains" = "some phrase to ignore"
    "unit.not_starts_with" = "sys-"
    "unit.not_ends_with" = ".device"

    # Checks whether a string field contains a string argument. This may be a
    # single string or a list of strings, in which case this evaluates to true if
    # any of the list matches.
    #
    # * optional
    # * no default
    # * type: string
    # * relevant when type = "check_fields"
    "message.contains" = "foo"
    "message.contains" = ["foo", "bar"]

    # Checks whether a string field ends with a string argument. This may be a
    # single string or a list of strings, in which case this evaluates to true if
    # any of the list matches.
    #
    # * optional
    # * no default
    # * type: string
    # * relevant when type = "check_fields"
    "environment.ends_with" = "-staging"
    "environment.ends_with" = ["-staging", "-running"]

    # Checks whether an IP field is contained within a given IP CIDR (works with
    # IPv4 and IPv6). This may be a single string or a list of strings, in which
    # case this evaluates to true if the IP field is contained within any of the
    # CIDRs in the list.
    #
    # * optional
    # * no default
    # * type: string
    # * relevant when type = "check_fields"
    "message.ip_cidr_contains" = "10.0.0.0/8"
    "message.ip_cidr_contains" = ["2000::/10", "192.168.0.0/16"]

    # Checks whether a string field matches a regular expression. Vector uses the
    # documented Rust Regex syntax. Note that this condition is considerably more
    # expensive than a regular string match (such as `starts_with` or `contains`)
    # so the use of those conditions are preferred where possible.
    #
    # * optional
    # * no default
    # * type: string
    # * relevant when type = "check_fields"
    "message.regex" = " (any|of|these|five|words) "

    # Checks whether a string field starts with a string argument. This may be a
    # single string or a list of strings, in which case this evaluates to true if
    # any of the list matches.
    #
    # * optional
    # * no default
    # * type: string
    # * relevant when type = "check_fields"
    "environment.starts_with" = "staging-"
    "environment.starts_with" = ["staging-", "running-"]

  #
  # General
  #

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "filter"
  type = "filter"

# Accepts and outputs `log` events, allowing you to enrich events with geolocation data from the MaxMind GeoIP2 and GeoLite2 city databases.
[transforms.geoip]
  # Path to the MaxMind GeoIP2 or GeoLite2 binary city database file
  # (`GeoLite2-City.mmdb`). Other databases, such as the the country database are
  # not supported.
  #
  # * required
  # * type: string
  database = "/path/to/GeoLite2-City.mmdb"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # The field name that contains the IP address. This field should contain a
  # valid IPv4 or IPv6 address.
  #
  # * required
  # * type: string
  source = "ip_address"
  source = "x-forwarded-for"
  source = "parent.child"
  source = "array[0]"

  # The default field to insert the resulting GeoIP data into. See output for
  # more info.
  #
  # * optional
  # * default: "geoip"
  # * type: string
  target = "geoip"
  target = "parent.child"

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "geoip"
  type = "geoip"

# Accepts and outputs `log` events, allowing you to parse a log field value with Grok.
[transforms.grok_parser]
  #
  # General
  #

  # If `true` will drop the specified `field` after parsing.
  #
  # * optional
  # * default: true
  # * type: bool
  drop_field = true
  drop_field = false

  # The log field to execute the `pattern` against. Must be a `string` value.
  #
  # * optional
  # * default: "message"
  # * type: string
  field = "message"
  field = "parent.child"
  field = "array[0]"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # The Grok pattern
  #
  # * required
  # * type: string
  pattern = "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{GREEDYDATA:message}"

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "grok_parser"
  type = "grok_parser"

  #
  # Types
  #

  [transforms.grok_parser.types]
    # A definition of log field type conversions. They key is the log field name
    # and the value is the type. `strptime` specifiers are supported for the
    # `timestamp` type.
    #
    # * optional
    # * no default
    # * type: string
    # * enum: "bool", "float", "int", "string", and "timestamp"
    status = "int"
    duration = "float"
    success = "bool"
    timestamp = "timestamp|%F"
    timestamp = "timestamp|%a %b %e %T %Y"
    parent = {child = "int"}

# Accepts and outputs `log` events, allowing you to parse a log field value as JSON.
[transforms.json_parser]
  # If the specified `field` should be dropped (removed) after parsing. If
  # parsing fails, the field will not be removed, irrespective of this setting.
  #
  # * optional
  # * default: true
  # * type: bool
  drop_field = true
  drop_field = false

  # If `true` events with invalid JSON will be dropped, otherwise the event will
  # be kept and passed through.
  #
  # * required
  # * type: bool
  drop_invalid = true

  # The log field to decode as JSON. Must be a `string` value type.
  #
  # * optional
  # * default: "message"
  # * type: string
  field = "message"
  field = "parent.child"
  field = "array[0]"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # If `target_field` is set and the log contains a field of the same name as the
  # target, it will only be overwritten if this is set to `true`.
  #
  # * optional
  # * default: false
  # * type: bool
  overwrite_target = false
  overwrite_target = true

  # If this setting is present, the parsed JSON will be inserted into the log as
  # a sub-object with this name. If a field with the same name already exists,
  # the parser will fail and produce an error.
  #
  # * optional
  # * no default
  # * type: string
  target_field = "root_field"
  target_field = "parent.child"

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "json_parser"
  type = "json_parser"

# Accepts `log` events, but outputs `metric` events, allowing you to convert logs into one or more metrics.
[transforms.log_to_metric]
  #
  # General
  #

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "log_to_metric"
  type = "log_to_metric"

  #
  # Metrics
  #

  [[transforms.log_to_metric.metrics]]

    # The log field to use as the metric.
    #
    # * required
    # * type: string
    field = "duration"
    field = "parent.child"

    # If `true` the metric will be incremented by the `field` value. If `false` the
    # metric will be incremented by 1 regardless of the `field` value.
    #
    # * optional
    # * default: false
    # * type: bool
    # * relevant when type = "counter"
    increment_by_value = false
    increment_by_value = true

    # The name of the metric. Defaults to `<field>_total` for `counter` and
    # `<field>` for `gauge`.
    #
    # * required
    # * type: string
    name = "duration_total"

    # The metric type.
    #
    # * required
    # * type: string
    # * enum: "counter", "gauge", "histogram", and "set"
    type = "counter"
    type = "gauge"
    type = "histogram"
    type = "set"


    [transforms.log_to_metric.metrics.tags]
      # Key/value pairs representing metric tags. Environment variables and field
      # interpolation is allowed.
      #
      # * required
      # * type: string
      host = "${HOSTNAME}"
      region = "us-east-1"
      status = "{{status}}"

# Accepts and outputs `log` events, allowing you to parse a log field's value in the logfmt format.
[transforms.logfmt_parser]
  #
  # General
  #

  # If the specified `field` should be dropped (removed) after parsing.
  #
  # * optional
  # * default: true
  # * type: bool
  drop_field = true
  drop_field = false

  # The log field to parse.
  #
  # * optional
  # * default: "message"
  # * type: string
  field = "message"
  field = "parent.child"
  field = "array[0]"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "logfmt_parser"
  type = "logfmt_parser"

  #
  # Types
  #

  [transforms.logfmt_parser.types]
    # A definition of log field type conversions. They key is the log field name
    # and the value is the type. `strptime` specifiers are supported for the
    # `timestamp` type.
    #
    # * optional
    # * no default
    # * type: string
    # * enum: "bool", "float", "int", "string", and "timestamp"
    status = "int"
    duration = "float"
    success = "bool"
    timestamp = "timestamp|%F"
    timestamp = "timestamp|%a %b %e %T %Y"
    parent = {child = "int"}

# Accepts and outputs `log` and `metric` events, allowing you to transform events with a full embedded Lua engine.
[transforms.lua]
  #
  # Hooks
  #

  [transforms.lua.hooks]
    # A function which is called when the first event comes, before calling
    # `hooks.process`
    #
    # * optional
    # * no default
    # * type: string
    init = "init"
    init = "init"

    # A function which is called for each incoming event. It can produce new events
    # using `emit` function.
    #
    # * required
    # * type: string
    process = """
  function (event, emit)
    event.log.field = "value" -- set value of a field
    event.log.another_field = nil -- remove field
    event.log.first, event.log.second = nil, event.log.first -- rename field

    -- Very important! Emit the processed event.
    emit(event)
  end
  """
    process = "process"
    process = "process"

    # A function which is called when Vector is stopped. It can produce new events
    # using `emit` function.
    #
    # * optional
    # * no default
    # * type: string
    shutdown = "shutdown"
    shutdown = "shutdown"

  #
  # General
  #

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # A list of directories to search when loading a Lua file via the `require`
  # function. If not specified, the modules are looked up in the directories of
  # Vector's configs.
  #
  # * optional
  # * no default
  # * type: [string]
  search_dirs = ["/etc/vector/lua"]

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "lua"
  type = "lua"

  # Transform API version. Specifying this version ensures that Vector does not
  # break backward compatibility.
  #
  # * required
  # * type: string
  # * must be: "2"
  version = "2"

  #
  # Source Code
  #

  # The source which is evaluated when the transform is created.
  #
  # * optional
  # * no default
  # * type: string
  source = """
function init()
  count = 0
end

function process()
  count = count + 1
end

function timer_handler(emit)
  emit(make_counter(counter))
  counter = 0
end

function shutdown(emit)
  emit(make_counter(counter))
end

function make_counter(value)
  return metric = {
    name = "event_counter",
    kind = "incremental",
    timestamp = os.date("!*t"),
    counter = {
      value = value
    }
  }
end
"""
  source = """
-- external file with hooks and timers defined
require('custom_module')
"""

  #
  # Timers
  #

  [[transforms.lua.timers]]
    # Defines a handler function which is executed periodially at
    # `interval_seconds`. It can produce new events using `emit` function.
    #
    # * required
    # * type: string
    handler = "timer_handler"

    # Defines the interval at which the timer handler would be executed.
    #
    # * required
    # * type: uint
    # * unit: seconds
    interval_seconds = 1
    interval_seconds = 10
    interval_seconds = 30

# Accepts and outputs `log` events, allowing you to merge partial log events into a single event.
[transforms.merge]
  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # Fields to merge. The values of these fields will be merged into the first
  # partial event. Fields not specified here will be ignored. Merging process
  # takes the first partial event and the base, then it merges in the fields from
  # each successive partial event, until a non-partial event arrives. Finally,
  # the non-partial event fields are merged in, producing the resulting merged
  # event.
  #
  # * optional
  # * default: ["message"]
  # * type: [string]
  merge_fields = ["message"]
  merge_fields = ["message", "parent.child"]

  # The field that indicates that the event is partial. A consequent stream of
  # partial events along with the first non-partial event will be merged together.
  #
  # * optional
  # * default: "_partial"
  # * type: string
  partial_event_marker_field = "_partial"
  partial_event_marker_field = "parent.child"

  # An ordered list of fields to distinguish streams by. Each stream has a
  # separate partial event merging state. Should be used to prevent events from
  # unrelated sources from mixing together, as this affects partial event
  # processing.
  #
  # * optional
  # * default: []
  # * type: [string]
  stream_discriminant_fields = ["host"]
  stream_discriminant_fields = ["host", "parent.child"]

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "merge"
  type = "merge"

# Accepts and outputs `log` events, allowing you to combine multiple events into a single event based on a set of identifiers.
[transforms.reduce]
  #
  # Ends when
  #

  [transforms.reduce.ends_when]
    # The type of the condition to execute.
    #
    # * optional
    # * default: "check_fields"
    # * type: string
    # * enum: "check_fields", "is_log", and "is_metric"
    type = "check_fields"
    type = "is_log"
    type = "is_metric"

    # Check whether a fields contents exactly matches the value specified. This may
    # be a single string or a list of strings, in which case this evaluates to true
    # if any of the list matches.
    #
    # * optional
    # * no default
    # * type: string
    # * relevant when type = "check_fields"
    "message.eq" = "this is the content to match against"
    "message.eq" = ["match this", "or this"]

    # Check whether a field exists or does not exist, depending on the provided
    # value being `true` or `false` respectively.
    #
    # * optional
    # * no default
    # * type: bool
    # * relevant when type = "check_fields"
    "host.exists" = true

    # Check whether a fields contents does not match the value specified. This may
    # be a single string or a list of strings, in which case this evaluates to
    # false if any of the list matches.
    #
    # * optional
    # * no default
    # * type: string
    # * relevant when type = "check_fields"
    "method.neq" = "POST"
    "method.neq" = ["POST", "GET"]

    # Check if the given `[condition]` does not match.
    #
    # * optional
    # * no default
    # * type: any
    # * relevant when type = "check_fields"
    "message.not_contains" = "some phrase to ignore"
    "unit.not_starts_with" = "sys-"
    "unit.not_ends_with" = ".device"

    # Checks whether a string field contains a string argument. This may be a
    # single string or a list of strings, in which case this evaluates to true if
    # any of the list matches.
    #
    # * optional
    # * no default
    # * type: string
    # * relevant when type = "check_fields"
    "message.contains" = "foo"
    "message.contains" = ["foo", "bar"]

    # Checks whether a string field ends with a string argument. This may be a
    # single string or a list of strings, in which case this evaluates to true if
    # any of the list matches.
    #
    # * optional
    # * no default
    # * type: string
    # * relevant when type = "check_fields"
    "environment.ends_with" = "-staging"
    "environment.ends_with" = ["-staging", "-running"]

    # Checks whether an IP field is contained within a given IP CIDR (works with
    # IPv4 and IPv6). This may be a single string or a list of strings, in which
    # case this evaluates to true if the IP field is contained within any of the
    # CIDRs in the list.
    #
    # * optional
    # * no default
    # * type: string
    # * relevant when type = "check_fields"
    "message.ip_cidr_contains" = "10.0.0.0/8"
    "message.ip_cidr_contains" = ["2000::/10", "192.168.0.0/16"]

    # Checks whether a string field matches a regular expression. Vector uses the
    # documented Rust Regex syntax. Note that this condition is considerably more
    # expensive than a regular string match (such as `starts_with` or `contains`)
    # so the use of those conditions are preferred where possible.
    #
    # * optional
    # * no default
    # * type: string
    # * relevant when type = "check_fields"
    "message.regex" = " (any|of|these|five|words) "

    # Checks whether a string field starts with a string argument. This may be a
    # single string or a list of strings, in which case this evaluates to true if
    # any of the list matches.
    #
    # * optional
    # * no default
    # * type: string
    # * relevant when type = "check_fields"
    "environment.starts_with" = "staging-"
    "environment.starts_with" = ["staging-", "running-"]

  #
  # General
  #

  # A maximum period of time to wait after the last event is received before a
  # combined event should be considered complete.
  #
  # * optional
  # * default: 30000
  # * type: int
  expire_after_ms = 30000

  # Controls the frequency that Vector checks for (and flushes) expired events.
  #
  # * optional
  # * default: 1000
  # * type: int
  flush_period_ms = 1000

  # An ordered list of fields by which to group events. Each group is combined
  # independently, allowing you to keep independent events separate. When no
  # fields are specified, all events will be combined in a single group. Events
  # missing a specified field will be combined in their own group.
  #
  # * optional
  # * default: []
  # * type: [string]
  identifier_fields = ["request_id"]
  identifier_fields = ["user_id", "transaction_id"]

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "reduce"
  type = "reduce"

  #
  # Merge strategies
  #

  [transforms.reduce.merge_strategies]
    # The custom merge strategy to use for a field.
    #
    # * required
    # * type: string
    # * enum: "array", "concat", "discard", "sum", "max", and "min"
    method = "discard"
    path = "discard"
    duration_ms = "sum"
    query = "array"

# Accepts and outputs `log` events, allowing you to parse a log field's value with a Regular Expression.
[transforms.regex_parser]
  #
  # General
  #

  # If the specified `field` should be dropped (removed) after parsing.
  #
  # * optional
  # * default: true
  # * type: bool
  drop_field = true
  drop_field = false

  # The log field to parse.
  #
  # * optional
  # * default: "message"
  # * type: string
  field = "message"
  field = "parent.child"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # If `target_field` is set and the log contains a field of the same name as the
  # target, it will only be overwritten if this is set to `true`.
  #
  # * optional
  # * default: true
  # * type: bool
  overwrite_target = true
  overwrite_target = false

  # The Regular Expressions to apply. Do not include the leading or trailing `/`
  # in any of the expressions.
  #
  # * required
  # * type: string
  patterns = "['^(?P<timestamp>[\\w\\-:\\+]+) (?P<level>\\w+) (?P<message>.*)$']"

  # If this setting is present, the parsed fields will be inserted into the log
  # as a sub-object with this name. If a field with the same name already exists,
  # the parser will fail and produce an error.
  #
  # * optional
  # * no default
  # * type: string
  target_field = "root_field"
  target_field = "parent.child"

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "regex_parser"
  type = "regex_parser"

  #
  # Types
  #

  [transforms.regex_parser.types]
    # A definition of log field type conversions. They key is the log field name
    # and the value is the type. `strptime` specifiers are supported for the
    # `timestamp` type.
    #
    # * optional
    # * no default
    # * type: string
    # * enum: "bool", "float", "int", "string", and "timestamp"
    status = "int"
    duration = "float"
    success = "bool"
    timestamp = "timestamp|%F"
    timestamp = "timestamp|%a %b %e %T %Y"
    parent = {child = "int"}

# Accepts and outputs `log` events, allowing you to remove one or more log fields.
[transforms.remove_fields]
  # If set to `true`, after removing fields, remove any parent objects that are
  # now empty.
  #
  # * optional
  # * default: false
  # * type: bool
  drop_empty = false
  drop_empty = true

  # The log field names to drop.
  #
  # * required
  # * type: [string]
  fields = ["field1", "field2", "parent.child"]

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "remove_fields"
  type = "remove_fields"

# Accepts and outputs `metric` events, allowing you to remove one or more metric tags.
[transforms.remove_tags]
  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # The tag names to drop.
  #
  # * required
  # * type: [string]
  tags = ["tag1", "tag2"]

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "remove_tags"
  type = "remove_tags"

# Accepts and outputs `log` events, allowing you to rename one or more log fields.
[transforms.rename_fields]
  #
  # General
  #

  # If set to `true`, after renaming fields, remove any parent objects of the old
  # field that are now empty.
  #
  # * optional
  # * default: false
  # * type: bool
  drop_empty = false
  drop_empty = true

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "rename_fields"
  type = "rename_fields"

  #
  # Fields
  #

  [transforms.rename_fields.fields]
    # Old-key/New-key pair reprsenting the key to be moved.
    #
    # * required
    # * type: *
    old_field_name = "new_field_name"
    parent = {old_child_name = "parent.new_child_name"}

# Accepts and outputs `log` events, allowing you to sample events with a configurable rate.
[transforms.sampler]
  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # The name of the log field to use to determine if the event should be passed.
  # This defaults to the global `message_key` option.
  #
  # * optional
  # * no default
  # * type: string
  key_field = "message"

  # A list of regular expression patterns to exclude events from sampling. If an
  # event's key field (see `key_field`) matches _any_ of these patterns it will
  # _not_ be sampled.
  #
  # * optional
  # * no default
  # * type: [string]
  pass_list = ["[error]", "field2"]

  # The rate at which events will be forwarded, expressed as 1/N. For example,
  # `rate = 10` means 1 out of every 10 events will be forwarded and the rest
  # will be dropped.
  #
  # * required
  # * type: uint
  rate = 10

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "sampler"
  type = "sampler"

# Accepts and outputs `log` events, allowing you to split a field's value on a _literal_ separator and zip the tokens into ordered field names.
[transforms.split]
  #
  # General
  #

  # If `true` the `field` will be dropped after parsing.
  #
  # * optional
  # * default: true
  # * type: bool
  drop_field = true
  drop_field = false

  # The field to apply the split on.
  #
  # * optional
  # * default: "message"
  # * type: string
  field = "message"
  field = "parent.child"

  # The field names assigned to the resulting tokens, in order.
  #
  # * required
  # * type: [string]
  field_names = ["timestamp", "level", "message", "parent.child"]

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # The separator to split the field on. If no separator is given, it will split
  # on all whitespace. 'Whitespace' is defined according to the terms of the
  # Unicode Derived Core Property `White_Space`.
  #
  # * optional
  # * default: "[whitespace]"
  # * type: [string]
  separator = ","

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "split"
  type = "split"

  #
  # Types
  #

  [transforms.split.types]
    # A definition of log field type conversions. They key is the log field name
    # and the value is the type. `strptime` specifiers are supported for the
    # `timestamp` type.
    #
    # * optional
    # * no default
    # * type: string
    # * enum: "bool", "float", "int", "string", and "timestamp"
    status = "int"
    duration = "float"
    success = "bool"
    timestamp = "timestamp|%F"
    timestamp = "timestamp|%a %b %e %T %Y"
    parent = {child = "int"}

# Accepts and outputs `log` events, allowing you to route events across parallel streams using logical filters.
[transforms.swimlanes]
  #
  # General
  #

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "swimlanes"
  type = "swimlanes"

  #
  # Lanes
  #

  [transforms.swimlanes.lanes]
    [transforms.swimlanes.lanes.`[swimlane-id]`]
      # The type of the condition to execute.
      #
      # * optional
      # * default: "check_fields"
      # * type: string
      # * enum: "check_fields", "is_log", and "is_metric"
      type = "check_fields"
      type = "is_log"
      type = "is_metric"

      # Check whether a fields contents exactly matches the value specified. This may
      # be a single string or a list of strings, in which case this evaluates to true
      # if any of the list matches.
      #
      # * optional
      # * no default
      # * type: string
      # * relevant when type = "check_fields"
      "message.eq" = "this is the content to match against"
      "message.eq" = ["match this", "or this"]

      # Check whether a field exists or does not exist, depending on the provided
      # value being `true` or `false` respectively.
      #
      # * optional
      # * no default
      # * type: bool
      # * relevant when type = "check_fields"
      "host.exists" = true

      # Check whether a fields contents does not match the value specified. This may
      # be a single string or a list of strings, in which case this evaluates to
      # false if any of the list matches.
      #
      # * optional
      # * no default
      # * type: string
      # * relevant when type = "check_fields"
      "method.neq" = "POST"
      "method.neq" = ["POST", "GET"]

      # Check if the given `[condition]` does not match.
      #
      # * optional
      # * no default
      # * type: any
      # * relevant when type = "check_fields"
      "message.not_contains" = "some phrase to ignore"
      "unit.not_starts_with" = "sys-"
      "unit.not_ends_with" = ".device"

      # Checks whether a string field contains a string argument. This may be a
      # single string or a list of strings, in which case this evaluates to true if
      # any of the list matches.
      #
      # * optional
      # * no default
      # * type: string
      # * relevant when type = "check_fields"
      "message.contains" = "foo"
      "message.contains" = ["foo", "bar"]

      # Checks whether a string field ends with a string argument. This may be a
      # single string or a list of strings, in which case this evaluates to true if
      # any of the list matches.
      #
      # * optional
      # * no default
      # * type: string
      # * relevant when type = "check_fields"
      "environment.ends_with" = "-staging"
      "environment.ends_with" = ["-staging", "-running"]

      # Checks whether an IP field is contained within a given IP CIDR (works with
      # IPv4 and IPv6). This may be a single string or a list of strings, in which
      # case this evaluates to true if the IP field is contained within any of the
      # CIDRs in the list.
      #
      # * optional
      # * no default
      # * type: string
      # * relevant when type = "check_fields"
      "message.ip_cidr_contains" = "10.0.0.0/8"
      "message.ip_cidr_contains" = ["2000::/10", "192.168.0.0/16"]

      # Checks whether a string field matches a regular expression. Vector uses the
      # documented Rust Regex syntax. Note that this condition is considerably more
      # expensive than a regular string match (such as `starts_with` or `contains`)
      # so the use of those conditions are preferred where possible.
      #
      # * optional
      # * no default
      # * type: string
      # * relevant when type = "check_fields"
      "message.regex" = " (any|of|these|five|words) "

      # Checks whether a string field starts with a string argument. This may be a
      # single string or a list of strings, in which case this evaluates to true if
      # any of the list matches.
      #
      # * optional
      # * no default
      # * type: string
      # * relevant when type = "check_fields"
      "environment.starts_with" = "staging-"
      "environment.starts_with" = ["staging-", "running-"]

# Accepts and outputs `metric` events, allowing you to limit the cardinality of metric tags to prevent downstream disruption of metrics services.
[transforms.tag_cardinality_limit]
  # The size of the cache in bytes to use to detect duplicate tags. The bigger
  # the cache the less likely it is to have a 'false positive' or a case where we
  # allow a new value for tag even after we have reached the configured limits.
  #
  # * optional
  # * default: 5120000
  # * type: uint
  # * unit: bytes
  # * relevant when mode = "probabilistic"
  cache_size_per_tag = 5120000

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # Controls what should happen when a metric comes in with a tag that would
  # exceed the configured limit on cardinality.
  #
  # * optional
  # * default: "drop_tag"
  # * type: string
  # * enum: "drop_tag" or "drop_event"
  limit_exceeded_action = "drop_tag"
  limit_exceeded_action = "drop_event"

  # Controls what approach is used internally to keep track of previously seen
  # tags and deterime when a tag on an incoming metric exceeds the limit.
  #
  # * required
  # * type: string
  # * enum: "exact" or "probabilistic"
  mode = "exact"
  mode = "probabilistic"

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "tag_cardinality_limit"
  type = "tag_cardinality_limit"

  # How many distinct values to accept for any given key.
  #
  # * optional
  # * default: 500
  # * type: uint
  value_limit = 500

# Accepts and outputs `log` events, allowing you to tokenize a field's value by splitting on white space, ignoring special wrapping characters, and zip the tokens into ordered field names.
[transforms.tokenizer]
  #
  # General
  #

  # If `true` the `field` will be dropped after parsing.
  #
  # * optional
  # * default: true
  # * type: bool
  drop_field = true
  drop_field = false

  # The log field to tokenize.
  #
  # * optional
  # * default: "message"
  # * type: string
  field = "message"
  field = "parent.child"

  # The log field names assigned to the resulting tokens, in order.
  #
  # * required
  # * type: [string]
  field_names = ["timestamp", "level", "message", "parent.child"]

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "tokenizer"
  type = "tokenizer"

  #
  # Types
  #

  [transforms.tokenizer.types]
    # A definition of log field type conversions. They key is the log field name
    # and the value is the type. `strptime` specifiers are supported for the
    # `timestamp` type.
    #
    # * optional
    # * no default
    # * type: string
    # * enum: "bool", "float", "int", "string", and "timestamp"
    status = "int"
    duration = "float"
    success = "bool"
    timestamp = "timestamp|%F"
    timestamp = "timestamp|%a %b %e %T %Y"
    parent = {child = "int"}

# Accepts and outputs `log` events, allowing you to execute **experimental** WASM plugins.
[transforms.wasm]
  # The directory where Vector should store the artifact it builds of this WASM
  # module. Typically, all WASM modules share this.
  #
  # * required
  # * type: string
  artifact_cache = "/etc/vector/artifacts"
  artifact_cache = "/var/lib/vector/artifacts"
  artifact_cache = "C:\\vector\\artifacts"

  # The maximum size of the heap of this module, in bytes. (This includes the
  # module itself, default is 10 MB.)
  #
  # * optional
  # * default: 10485760
  # * type: int
  heap_max_size = 10485760

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # The file path of the `.wasm` or `.wat` module.
  #
  # * required
  # * type: string
  module = "./modules/example.wasm"
  module = "/example.wat"
  module = "example.wasm"

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "wasm"
  type = "wasm"


# ------------------------------------------------------------------------------
# Sinks
# ------------------------------------------------------------------------------
# Sinks batch or stream data out of Vector.

# Batches `log` events to Amazon Web Service's CloudWatch Logs service via the `PutLogEvents` API endpoint.
[sinks.aws_cloudwatch_logs]
  #
  # General
  #

  # The ARN of an IAM role to assume at startup.
  #
  # * optional
  # * no default
  # * type: string
  assume_role = "arn:aws:iam::123456789098:role/my_role"

  # The compression strategy used to compress the encoded event data before
  # transmission.
  #
  # * optional
  # * default: "none"
  # * type: string
  # * enum: "none" or "gzip"
  compression = "none"
  compression = "gzip"

  # Dynamically create a log group if it does not already exist. This will ignore
  # `create_missing_stream` directly after creating the group and will create the
  # first stream.
  #
  # * optional
  # * default: true
  # * type: bool
  create_missing_group = true
  create_missing_group = false

  # Dynamically create a log stream if it does not already exist.
  #
  # * optional
  # * default: true
  # * type: bool
  create_missing_stream = true
  create_missing_stream = false

  # Custom endpoint for use with AWS-compatible services. Providing a value for
  # this option will make `region` moot.
  #
  # * optional
  # * no default
  # * type: string
  # * relevant when region = ""
  endpoint = "127.0.0.0:5000/path/to/service"

  # The group name of the target CloudWatch Logs stream.
  #
  # * required
  # * type: string
  group_name = "group-name"
  group_name = "{{ file }}"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # The AWS region of the target service. If `endpoint` is provided it will
  # override this value since the endpoint includes the region.
  #
  # * required
  # * type: string
  # * required when endpoint = ""
  region = "us-east-1"

  # The stream name of the target CloudWatch Logs stream.
  #
  # * required
  # * type: string
  stream_name = "{{ host }}"
  stream_name = "%Y-%m-%d"
  stream_name = "stream-name"

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "aws_cloudwatch_logs"
  type = "aws_cloudwatch_logs"

  #
  # Batch
  #

  [sinks.aws_cloudwatch_logs.batch]
    # The maximum size of a batch, in bytes, before it is flushed.
    #
    # * optional
    # * default: 1048576
    # * type: uint
    # * unit: bytes
    max_bytes = 1048576

    # The maximum size of a batch, in events, before it is flushed.
    #
    # * optional
    # * default: 10000
    # * type: uint
    # * unit: events
    max_events = 10000

    # The maximum age of a batch before it is flushed.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    timeout_secs = 1

  #
  # Buffer
  #

  [sinks.aws_cloudwatch_logs.buffer]
    # The maximum number of events allowed in the buffer.
    #
    # * optional
    # * default: 500
    # * type: uint
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * required
    # * type: uint
    # * unit: bytes
    # * required when type = "disk"
    max_size = 104900000

    # The buffer's type and storage mechanism.
    #
    # * optional
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Encoding
  #

  [sinks.aws_cloudwatch_logs.encoding]
    # The encoding codec used to serialize the events before outputting.
    #
    # * required
    # * type: string
    # * enum: "json" or "text"
    codec = "json"
    codec = "text"

    # Prevent the sink from encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    except_fields = ["timestamp", "message", "host"]

    # Limit the sink to only encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    only_fields = ["timestamp", "message", "host"]

    # How to format event timestamps.
    #
    # * optional
    # * default: "rfc3339"
    # * type: string
    # * enum: "rfc3339" or "unix"
    timestamp_format = "rfc3339"
    timestamp_format = "unix"

  #
  # Request
  #

  [sinks.aws_cloudwatch_logs.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 5
    # * type: uint
    # * unit: requests
    in_flight_limit = 5

    # The time window, in seconds, used for the `rate_limit_num` option.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # time window.
    #
    # * optional
    # * default: 5
    # * type: uint
    rate_limit_num = 5

    # The maximum number of retries to make for failed requests. The default, for
    # all intents and purposes, represents an infinite number of retries.
    #
    # * optional
    # * default: 18446744073709551615
    # * type: uint
    retry_attempts = 18446744073709551615

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time, in seconds, to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: uint
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 30
    # * type: uint
    # * unit: seconds
    timeout_secs = 30

# Streams `metric` events to Amazon Web Service's CloudWatch Metrics service via the `PutMetricData` API endpoint.
[sinks.aws_cloudwatch_metrics]
  #
  # General
  #

  # The ARN of an IAM role to assume at startup.
  #
  # * optional
  # * no default
  # * type: string
  assume_role = "arn:aws:iam::123456789098:role/my_role"

  # The compression strategy used to compress the encoded event data before
  # transmission.
  #
  # * optional
  # * default: "none"
  # * type: string
  # * enum: "none" or "gzip"
  compression = "none"
  compression = "gzip"

  # Custom endpoint for use with AWS-compatible services. Providing a value for
  # this option will make `region` moot.
  #
  # * optional
  # * no default
  # * type: string
  # * relevant when region = ""
  endpoint = "127.0.0.0:5000/path/to/service"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # A namespace that will isolate different metrics from each other.
  #
  # * required
  # * type: string
  namespace = "service"

  # The AWS region of the target service. If `endpoint` is provided it will
  # override this value since the endpoint includes the region.
  #
  # * required
  # * type: string
  # * required when endpoint = ""
  region = "us-east-1"

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "aws_cloudwatch_metrics"
  type = "aws_cloudwatch_metrics"

  #
  # Batch
  #

  [sinks.aws_cloudwatch_metrics.batch]
    # The maximum size of a batch, in events, before it is flushed.
    #
    # * optional
    # * default: 20
    # * type: uint
    # * unit: events
    max_events = 20

    # The maximum age of a batch before it is flushed.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    timeout_secs = 1

# Batches `log` events to Amazon Web Service's Kinesis Data Firehose via the `PutRecordBatch` API endpoint.
[sinks.aws_kinesis_firehose]
  #
  # General
  #

  # The ARN of an IAM role to assume at startup.
  #
  # * optional
  # * no default
  # * type: string
  assume_role = "arn:aws:iam::123456789098:role/my_role"

  # The compression strategy used to compress the encoded event data before
  # transmission.
  #
  # * optional
  # * default: "none"
  # * type: string
  # * enum: "none" or "gzip"
  compression = "none"
  compression = "gzip"

  # Custom endpoint for use with AWS-compatible services. Providing a value for
  # this option will make `region` moot.
  #
  # * optional
  # * no default
  # * type: string
  # * relevant when region = ""
  endpoint = "127.0.0.0:5000/path/to/service"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # The AWS region of the target service. If `endpoint` is provided it will
  # override this value since the endpoint includes the region.
  #
  # * required
  # * type: string
  # * required when endpoint = ""
  region = "us-east-1"

  # The stream name of the target Kinesis Firehose delivery stream.
  #
  # * required
  # * type: string
  stream_name = "my-stream"

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "aws_kinesis_firehose"
  type = "aws_kinesis_firehose"

  #
  # Batch
  #

  [sinks.aws_kinesis_firehose.batch]
    # The maximum size of a batch, in events, before it is flushed.
    #
    # * optional
    # * default: 500
    # * type: uint
    # * unit: events
    max_events = 500

    # The maximum age of a batch before it is flushed.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    timeout_secs = 1

  #
  # Buffer
  #

  [sinks.aws_kinesis_firehose.buffer]
    # The maximum number of events allowed in the buffer.
    #
    # * optional
    # * default: 500
    # * type: uint
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * required
    # * type: uint
    # * unit: bytes
    # * required when type = "disk"
    max_size = 104900000

    # The buffer's type and storage mechanism.
    #
    # * optional
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Encoding
  #

  [sinks.aws_kinesis_firehose.encoding]
    # The encoding codec used to serialize the events before outputting.
    #
    # * required
    # * type: string
    # * enum: "json" or "text"
    codec = "json"
    codec = "text"

    # Prevent the sink from encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    except_fields = ["timestamp", "message", "host"]

    # Limit the sink to only encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    only_fields = ["timestamp", "message", "host"]

    # How to format event timestamps.
    #
    # * optional
    # * default: "rfc3339"
    # * type: string
    # * enum: "rfc3339" or "unix"
    timestamp_format = "rfc3339"
    timestamp_format = "unix"

  #
  # Request
  #

  [sinks.aws_kinesis_firehose.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 5
    # * type: uint
    # * unit: requests
    in_flight_limit = 5

    # The time window, in seconds, used for the `rate_limit_num` option.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # time window.
    #
    # * optional
    # * default: 5
    # * type: uint
    rate_limit_num = 5

    # The maximum number of retries to make for failed requests. The default, for
    # all intents and purposes, represents an infinite number of retries.
    #
    # * optional
    # * default: 18446744073709551615
    # * type: uint
    retry_attempts = 18446744073709551615

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time, in seconds, to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: uint
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 30
    # * type: uint
    # * unit: seconds
    timeout_secs = 30

# Batches `log` events to Amazon Web Service's Kinesis Data Stream service via the `PutRecords` API endpoint.
[sinks.aws_kinesis_streams]
  #
  # General
  #

  # The ARN of an IAM role to assume at startup.
  #
  # * optional
  # * no default
  # * type: string
  assume_role = "arn:aws:iam::123456789098:role/my_role"

  # The compression strategy used to compress the encoded event data before
  # transmission.
  #
  # * optional
  # * default: "none"
  # * type: string
  # * enum: "none" or "gzip"
  compression = "none"
  compression = "gzip"

  # Custom endpoint for use with AWS-compatible services. Providing a value for
  # this option will make `region` moot.
  #
  # * optional
  # * no default
  # * type: string
  # * relevant when region = ""
  endpoint = "127.0.0.0:5000/path/to/service"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # The log field used as the Kinesis record's partition key value.
  #
  # * optional
  # * no default
  # * type: string
  partition_key_field = "user_id"

  # The AWS region of the target service. If `endpoint` is provided it will
  # override this value since the endpoint includes the region.
  #
  # * required
  # * type: string
  # * required when endpoint = ""
  region = "us-east-1"

  # The stream name of the target Kinesis Logs stream.
  #
  # * required
  # * type: string
  stream_name = "my-stream"

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "aws_kinesis_streams"
  type = "aws_kinesis_streams"

  #
  # Batch
  #

  [sinks.aws_kinesis_streams.batch]
    # The maximum size of a batch, in events, before it is flushed.
    #
    # * optional
    # * default: 500
    # * type: uint
    # * unit: events
    max_events = 500

    # The maximum age of a batch before it is flushed.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    timeout_secs = 1

  #
  # Buffer
  #

  [sinks.aws_kinesis_streams.buffer]
    # The maximum number of events allowed in the buffer.
    #
    # * optional
    # * default: 500
    # * type: uint
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * required
    # * type: uint
    # * unit: bytes
    # * required when type = "disk"
    max_size = 104900000

    # The buffer's type and storage mechanism.
    #
    # * optional
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Encoding
  #

  [sinks.aws_kinesis_streams.encoding]
    # The encoding codec used to serialize the events before outputting.
    #
    # * required
    # * type: string
    # * enum: "json" or "text"
    codec = "json"
    codec = "text"

    # Prevent the sink from encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    except_fields = ["timestamp", "message", "host"]

    # Limit the sink to only encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    only_fields = ["timestamp", "message", "host"]

    # How to format event timestamps.
    #
    # * optional
    # * default: "rfc3339"
    # * type: string
    # * enum: "rfc3339" or "unix"
    timestamp_format = "rfc3339"
    timestamp_format = "unix"

  #
  # Request
  #

  [sinks.aws_kinesis_streams.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 5
    # * type: uint
    # * unit: requests
    in_flight_limit = 5

    # The time window, in seconds, used for the `rate_limit_num` option.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # time window.
    #
    # * optional
    # * default: 5
    # * type: uint
    rate_limit_num = 5

    # The maximum number of retries to make for failed requests. The default, for
    # all intents and purposes, represents an infinite number of retries.
    #
    # * optional
    # * default: 18446744073709551615
    # * type: uint
    retry_attempts = 18446744073709551615

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time, in seconds, to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: uint
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 30
    # * type: uint
    # * unit: seconds
    timeout_secs = 30

# Batches `log` events to Amazon Web Service's S3 service via the `PutObject` API endpoint.
[sinks.aws_s3]
  #
  # ACL
  #

  # Canned ACL to apply to the created objects. For more information, see Canned
  # ACL.
  #
  # * optional
  # * no default
  # * type: string
  # * enum: "private", "public-read", "public-read-write", "aws-exec-read", "authenticated-read", and "log-delivery-write"
  acl = "private"
  acl = "public-read"
  acl = "public-read-write"
  acl = "aws-exec-read"
  acl = "authenticated-read"
  acl = "log-delivery-write"

  # Gives the named grantee READ, READ_ACP, and WRITE_ACP permissions on the
  # created objects.
  #
  # * optional
  # * no default
  # * type: string
  grant_full_control = "79a59df900b949e55d96a1e698fbacedfd6e09d98eacf8f8d5218e7cd47ef2be"
  grant_full_control = "person@email.com"
  grant_full_control = "http://acs.amazonaws.com/groups/global/AllUsers"

  # Allows the named grantee to read the created objects and their metadata.
  #
  # * optional
  # * no default
  # * type: string
  grant_read = "79a59df900b949e55d96a1e698fbacedfd6e09d98eacf8f8d5218e7cd47ef2be"
  grant_read = "person@email.com"
  grant_read = "http://acs.amazonaws.com/groups/global/AllUsers"

  # Allows the named grantee to read the created objects' ACL.
  #
  # * optional
  # * no default
  # * type: string
  grant_read_acp = "79a59df900b949e55d96a1e698fbacedfd6e09d98eacf8f8d5218e7cd47ef2be"
  grant_read_acp = "person@email.com"
  grant_read_acp = "http://acs.amazonaws.com/groups/global/AllUsers"

  # Allows the named grantee to write the created objects' ACL.
  #
  # * optional
  # * no default
  # * type: string
  grant_write_acp = "79a59df900b949e55d96a1e698fbacedfd6e09d98eacf8f8d5218e7cd47ef2be"
  grant_write_acp = "person@email.com"
  grant_write_acp = "http://acs.amazonaws.com/groups/global/AllUsers"

  #
  # General
  #

  # The ARN of an IAM role to assume at startup.
  #
  # * optional
  # * no default
  # * type: string
  assume_role = "arn:aws:iam::123456789098:role/my_role"

  # The S3 bucket name. Do not include a leading `s3://` or a trailing `/`.
  #
  # * required
  # * type: string
  bucket = "my-bucket"

  # The compression strategy used to compress the encoded event data before
  # transmission.
  #
  # * optional
  # * default: "gzip"
  # * type: string
  # * enum: "none" or "gzip"
  compression = "none"
  compression = "gzip"

  # Custom endpoint for use with AWS-compatible services. Providing a value for
  # this option will make `region` moot.
  #
  # * optional
  # * no default
  # * type: string
  # * relevant when region = ""
  endpoint = "127.0.0.0:5000/path/to/service"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # The AWS region of the target service. If `endpoint` is provided it will
  # override this value since the endpoint includes the region.
  #
  # * required
  # * type: string
  # * required when endpoint = ""
  region = "us-east-1"

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "aws_s3"
  type = "aws_s3"

  #
  # Batch
  #

  [sinks.aws_s3.batch]
    # The maximum size of a batch, in bytes, before it is flushed.
    #
    # * optional
    # * default: 10000000
    # * type: uint
    # * unit: bytes
    max_bytes = 10000000

    # The maximum size of a batch, in events, before it is flushed.
    #
    # * optional
    # * no default
    # * type: uint
    # * unit: events
    max_events = 1000

    # The maximum age of a batch before it is flushed.
    #
    # * optional
    # * default: 300
    # * type: uint
    # * unit: seconds
    timeout_secs = 300

  #
  # Buffer
  #

  [sinks.aws_s3.buffer]
    # The maximum number of events allowed in the buffer.
    #
    # * optional
    # * default: 500
    # * type: uint
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * required
    # * type: uint
    # * unit: bytes
    # * required when type = "disk"
    max_size = 104900000

    # The buffer's type and storage mechanism.
    #
    # * optional
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Content Type
  #

  # Specifies what content encodings have been applied to the object and thus
  # what decoding mechanisms must be applied to obtain the media-type referenced
  # by the Content-Type header field. By default calculated from `compression`
  # value.
  #
  # * optional
  # * no default
  # * type: string
  content_encoding = "gzip"

  # A standard MIME type describing the format of the contents.
  #
  # * optional
  # * default: "text/x-log"
  # * type: string
  content_type = "text/x-log"

  #
  # Encoding
  #

  [sinks.aws_s3.encoding]
    # The encoding codec used to serialize the events before outputting.
    #
    # * optional
    # * default: "text"
    # * type: string
    # * enum: "ndjson" or "text"
    codec = "ndjson"
    codec = "text"

    # Prevent the sink from encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    except_fields = ["timestamp", "message", "host"]

    # Limit the sink to only encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    only_fields = ["timestamp", "message", "host"]

    # How to format event timestamps.
    #
    # * optional
    # * default: "rfc3339"
    # * type: string
    # * enum: "rfc3339" or "unix"
    timestamp_format = "rfc3339"
    timestamp_format = "unix"

  #
  # Naming
  #

  # Whether or not to append a UUID v4 token to the end of the file. This ensures
  # there are no name collisions high volume use cases.
  #
  # * optional
  # * default: true
  # * type: bool
  filename_append_uuid = true
  filename_append_uuid = false

  # The filename extension to use in the object name.
  #
  # * optional
  # * default: "log"
  # * type: string
  filename_extension = "log"

  # The format of the resulting object file name. `strftime` specifiers are
  # supported.
  #
  # * optional
  # * default: "%s"
  # * type: string
  filename_time_format = "%s"

  # A prefix to apply to all object key names. This should be used to partition
  # your objects, and it's important to end this value with a `/` if you want
  # this to be the root S3 "folder".
  #
  # * optional
  # * default: "date=%F/"
  # * type: string
  key_prefix = "date=%F/"
  key_prefix = "date=%F/hour=%H/"
  key_prefix = "year=%Y/month=%m/day=%d/"
  key_prefix = "application_id={{ application_id }}/date=%F/"

  #
  # Request
  #

  [sinks.aws_s3.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 50
    # * type: uint
    # * unit: requests
    in_flight_limit = 50

    # The time window, in seconds, used for the `rate_limit_num` option.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # time window.
    #
    # * optional
    # * default: 250
    # * type: uint
    rate_limit_num = 250

    # The maximum number of retries to make for failed requests. The default, for
    # all intents and purposes, represents an infinite number of retries.
    #
    # * optional
    # * default: 18446744073709551615
    # * type: uint
    retry_attempts = 18446744073709551615

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time, in seconds, to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: uint
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 30
    # * type: uint
    # * unit: seconds
    timeout_secs = 30

  #
  # Encryption
  #

  # The server-side encryption algorithm used when storing these objects.
  #
  # * optional
  # * no default
  # * type: string
  # * enum: "AES256" or "aws:kms"
  server_side_encryption = "AES256"
  server_side_encryption = "aws:kms"

  # If `server_side_encryption` has the value `"aws.kms"`, this specifies the ID
  # of the AWS Key Management Service (AWS KMS) symmetrical customer managed
  # customer master key (CMK) that will used for the created objects. If not
  # specified, Amazon S3 uses the AWS managed CMK in AWS to protect the data.
  #
  # * optional
  # * no default
  # * type: string
  # * relevant when server_side_encryption = "aws:kms"
  ssekms_key_id = "abcd1234"

  #
  # Storage
  #

  # The storage class for the created objects. See the S3 Storage Classes for
  # more details.
  #
  # * optional
  # * no default
  # * type: string
  # * enum: "STANDARD", "REDUCED_REDUNDANCY", "INTELLIGENT_TIERING", "STANDARD_IA", "ONEZONE_IA", "GLACIER", and "DEEP_ARCHIVE"
  storage_class = "STANDARD"
  storage_class = "REDUCED_REDUNDANCY"
  storage_class = "INTELLIGENT_TIERING"
  storage_class = "STANDARD_IA"
  storage_class = "ONEZONE_IA"
  storage_class = "GLACIER"
  storage_class = "DEEP_ARCHIVE"

  #
  # Metadata
  #

  [sinks.aws_s3.tags]
    # A custom tag to be added to the created objects.
    #
    # * optional
    # * no default
    # * type: string
    Tag1 = "Value1"

# Streams `log` and `metric` events to a blackhole that simply discards data, designed for testing and benchmarking purposes.
[sinks.blackhole]
  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # The number of events that must be received in order to print a summary of
  # activity.
  #
  # * required
  # * type: uint
  print_amount = 1000

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "blackhole"
  type = "blackhole"

# Batches `log` events to Clickhouse via the `HTTP` Interface.
[sinks.clickhouse]
  #
  # Auth
  #

  [sinks.clickhouse.auth]
    # The basic authentication password.
    #
    # * required
    # * type: string
    # * required when strategy = "basic"
    password = "${CLICKHOUSE_PASSWORD}"
    password = "password"

    # The authentication strategy to use.
    #
    # * required
    # * type: string
    # * enum: "basic" or "bearer"
    strategy = "basic"
    strategy = "bearer"

    # The token to use for bearer authentication
    #
    # * required
    # * type: string
    # * required when strategy = "bearer"
    token = "${API_TOKEN}"
    token = "xyz123"

    # The basic authentication user name.
    #
    # * required
    # * type: string
    # * required when strategy = "basic"
    user = "${CLICKHOUSE_USERNAME}"
    user = "username"

  #
  # Batch
  #

  [sinks.clickhouse.batch]
    # The maximum size of a batch, in bytes, before it is flushed.
    #
    # * optional
    # * default: 1049000
    # * type: uint
    # * unit: bytes
    max_bytes = 1049000

    # The maximum size of a batch, in events, before it is flushed.
    #
    # * optional
    # * no default
    # * type: uint
    # * unit: events
    max_events = 1000

    # The maximum age of a batch before it is flushed.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    timeout_secs = 1

  #
  # Buffer
  #

  [sinks.clickhouse.buffer]
    # The maximum number of events allowed in the buffer.
    #
    # * optional
    # * default: 500
    # * type: uint
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * required
    # * type: uint
    # * unit: bytes
    # * required when type = "disk"
    max_size = 104900000

    # The buffer's type and storage mechanism.
    #
    # * optional
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Requests
  #

  # The compression strategy used to compress the encoded event data before
  # transmission.
  #
  # * optional
  # * default: "gzip"
  # * type: string
  # * enum: "none" or "gzip"
  compression = "none"
  compression = "gzip"

  #
  # General
  #

  # The database that contains the stable that data will be inserted into.
  #
  # * optional
  # * no default
  # * type: string
  database = "mydatabase"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # The host url of the Clickhouse server.
  #
  # * required
  # * type: string
  host = "http://localhost:8123"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # The table that data will be inserted into.
  #
  # * required
  # * type: string
  table = "mytable"

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "clickhouse"
  type = "clickhouse"

  #
  # Encoding
  #

  [sinks.clickhouse.encoding]
    # Prevent the sink from encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    except_fields = ["timestamp", "message", "host"]

    # Limit the sink to only encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    only_fields = ["timestamp", "message", "host"]

    # How to format event timestamps.
    #
    # * optional
    # * default: "rfc3339"
    # * type: string
    # * enum: "rfc3339" or "unix"
    timestamp_format = "rfc3339"
    timestamp_format = "unix"

  #
  # Request
  #

  [sinks.clickhouse.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 5
    # * type: uint
    # * unit: requests
    in_flight_limit = 5

    # The time window, in seconds, used for the `rate_limit_num` option.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # time window.
    #
    # * optional
    # * default: 5
    # * type: uint
    rate_limit_num = 5

    # The maximum number of retries to make for failed requests. The default, for
    # all intents and purposes, represents an infinite number of retries.
    #
    # * optional
    # * default: 18446744073709551615
    # * type: uint
    retry_attempts = 18446744073709551615

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time, in seconds, to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: uint
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 30
    # * type: uint
    # * unit: seconds
    timeout_secs = 30

  #
  # TLS
  #

  [sinks.clickhouse.tls]
    # Absolute path to an additional CA certificate file, in DER or PEM format
    # (X.509), or an inline CA certificate in PEM format.
    #
    # * optional
    # * no default
    # * type: string
    ca_file = "/path/to/certificate_authority.crt"

    # Absolute path to a certificate file used to identify this connection, in DER
    # or PEM format (X.509) or PKCS#12, or an inline certificate in PEM format. If
    # this is set and is not a PKCS#12 archive, `key_file` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    crt_file = "/path/to/host_certificate.crt"

    # Absolute path to a private key file used to identify this connection, in DER
    # or PEM format (PKCS#8), or an inline private key in PEM format. If this is
    # set, `crt_file` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    key_file = "/path/to/host_certificate.key"

    # Pass phrase used to unlock the encrypted key file. This has no effect unless
    # `key_file` is set.
    #
    # * optional
    # * no default
    # * type: string
    key_pass = "${KEY_PASS_ENV_VAR}"
    key_pass = "PassWord1"

    # If `true` (the default), Vector will validate the TLS certificate of the
    # remote host.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_certificate = true
    verify_certificate = false

    # If `true` (the default), Vector will validate the configured remote host name
    # against the remote host's TLS certificate. Do NOT set this to `false` unless
    # you understand the risks of not verifying the remote hostname.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_hostname = true
    verify_hostname = false

# Streams `log` and `metric` events to standard output streams, such as STDOUT and STDERR.
[sinks.console]
  #
  # Encoding
  #

  [sinks.console.encoding]
    # The encoding codec used to serialize the events before outputting.
    #
    # * required
    # * type: string
    # * enum: "json" or "text"
    codec = "json"
    codec = "text"

    # Prevent the sink from encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    except_fields = ["timestamp", "message", "host"]

    # Limit the sink to only encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    only_fields = ["timestamp", "message", "host"]

    # How to format event timestamps.
    #
    # * optional
    # * default: "rfc3339"
    # * type: string
    # * enum: "rfc3339" or "unix"
    timestamp_format = "rfc3339"
    timestamp_format = "unix"

  #
  # General
  #

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # The standard stream to write to.
  #
  # * optional
  # * default: "stdout"
  # * type: string
  # * enum: "stdout" or "stderr"
  target = "stdout"
  target = "stderr"

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "console"
  type = "console"

# Streams `log` events to Datadog's logs via the TCP endpoint.
[sinks.datadog_logs]
  #
  # General
  #

  # Datadog API key
  #
  # * required
  # * type: string
  api_key = "${DATADOG_API_KEY_ENV_VAR}"
  api_key = "ef8d5de700e7989468166c40fc8a0ccd"

  # The endpoint to stream logs to.
  #
  # * optional
  # * default: "intake.logs.datadoghq.com:10516"
  # * type: string
  endpoint = "127.0.0.1:8080"
  endpoint = "example.com:12345"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "datadog_logs"
  type = "datadog_logs"

  #
  # Buffer
  #

  [sinks.datadog_logs.buffer]
    # The maximum number of events allowed in the buffer.
    #
    # * optional
    # * default: 500
    # * type: uint
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * required
    # * type: uint
    # * unit: bytes
    # * required when type = "disk"
    max_size = 104900000

    # The buffer's type and storage mechanism.
    #
    # * optional
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Encoding
  #

  [sinks.datadog_logs.encoding]
    # The encoding codec used to serialize the events before outputting.
    #
    # * required
    # * type: string
    # * enum: "json" or "text"
    codec = "json"
    codec = "text"

    # Prevent the sink from encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    except_fields = ["timestamp", "message", "host"]

    # Limit the sink to only encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    only_fields = ["timestamp", "message", "host"]

    # How to format event timestamps.
    #
    # * optional
    # * default: "rfc3339"
    # * type: string
    # * enum: "rfc3339" or "unix"
    timestamp_format = "rfc3339"
    timestamp_format = "unix"

  #
  # TLS
  #

  [sinks.datadog_logs.tls]
    # Absolute path to an additional CA certificate file, in DER or PEM format
    # (X.509), or an inline CA certificate in PEM format.
    #
    # * optional
    # * no default
    # * type: string
    ca_file = "/path/to/certificate_authority.crt"

    # Absolute path to a certificate file used to identify this connection, in DER
    # or PEM format (X.509) or PKCS#12, or an inline certificate in PEM format. If
    # this is set and is not a PKCS#12 archive, `key_file` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    crt_file = "/path/to/host_certificate.crt"

    # Enable TLS during connections to the remote.
    #
    # * optional
    # * default: false
    # * type: bool
    enabled = false
    enabled = true

    # Absolute path to a private key file used to identify this connection, in DER
    # or PEM format (PKCS#8), or an inline private key in PEM format. If this is
    # set, `crt_file` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    key_file = "/path/to/host_certificate.key"

    # Pass phrase used to unlock the encrypted key file. This has no effect unless
    # `key_file` is set.
    #
    # * optional
    # * no default
    # * type: string
    key_pass = "${KEY_PASS_ENV_VAR}"
    key_pass = "PassWord1"

    # If `true` (the default), Vector will validate the TLS certificate of the
    # remote host.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_certificate = true
    verify_certificate = false

    # If `true` (the default), Vector will validate the configured remote host name
    # against the remote host's TLS certificate. Do NOT set this to `false` unless
    # you understand the risks of not verifying the remote hostname.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_hostname = true
    verify_hostname = false

# Batches `metric` events to Datadog's metrics service using HTTP API.
[sinks.datadog_metrics]
  #
  # General
  #

  # Datadog API key
  #
  # * required
  # * type: string
  api_key = "${DATADOG_API_KEY}"
  api_key = "ef8d5de700e7989468166c40fc8a0ccd"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # Datadog endpoint to send metrics to.
  #
  # * optional
  # * default: "https://api.datadoghq.com"
  # * type: string
  host = "https://api.datadoghq.com"
  host = "https://api.datadoghq.eu"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # A prefix that will be added to all metric names.
  #
  # * required
  # * type: string
  namespace = "service"

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "datadog_metrics"
  type = "datadog_metrics"

  #
  # Batch
  #

  [sinks.datadog_metrics.batch]
    # The maximum size of a batch, in events, before it is flushed.
    #
    # * optional
    # * default: 20
    # * type: uint
    # * unit: events
    max_events = 20

    # The maximum age of a batch before it is flushed.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    timeout_secs = 1

  #
  # Request
  #

  [sinks.datadog_metrics.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 5
    # * type: uint
    # * unit: requests
    in_flight_limit = 5

    # The time window, in seconds, used for the `rate_limit_num` option.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # time window.
    #
    # * optional
    # * default: 5
    # * type: uint
    rate_limit_num = 5

    # The maximum number of retries to make for failed requests. The default, for
    # all intents and purposes, represents an infinite number of retries.
    #
    # * optional
    # * default: 18446744073709551615
    # * type: uint
    retry_attempts = 18446744073709551615

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time, in seconds, to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: uint
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 60
    # * type: uint
    # * unit: seconds
    timeout_secs = 60

# Batches `log` events to Elasticsearch via the `_bulk` API endpoint.
[sinks.elasticsearch]
  #
  # Auth
  #

  [sinks.elasticsearch.auth]
    # The ARN of an IAM role to assume at startup.
    #
    # * optional
    # * no default
    # * type: string
    # * relevant when strategy = "aws"
    assume_role = "arn:aws:iam::123456789098:role/my_role"

    # The basic authentication password.
    #
    # * required
    # * type: string
    # * required when strategy = "basic"
    password = "${ELASTICSEARCH_PASSWORD}"
    password = "password"

    # The authentication strategy to use.
    #
    # * required
    # * type: string
    # * enum: "aws" or "basic"
    strategy = "aws"
    strategy = "basic"

    # The basic authentication user name.
    #
    # * required
    # * type: string
    # * required when strategy = "basic"
    user = "${ELASTICSEARCH_USERNAME}"
    user = "username"

  #
  # AWS
  #

  [sinks.elasticsearch.aws]
    # The AWS region of the target service. This defaults to the region named in
    # the host parameter, or the value of the `$AWS_REGION` or
    # `$AWS_DEFAULT_REGION` environment variables if that cannot be determined, or
    # "us-east-1".
    #
    # * optional
    # * no default
    # * type: string
    # * relevant when strategy = "aws"
    region = "us-east-1"

  #
  # Batch
  #

  [sinks.elasticsearch.batch]
    # The maximum size of a batch, in bytes, before it is flushed.
    #
    # * optional
    # * default: 10490000
    # * type: uint
    # * unit: bytes
    max_bytes = 10490000

    # The maximum size of a batch, in events, before it is flushed.
    #
    # * optional
    # * no default
    # * type: uint
    # * unit: events
    max_events = 1000

    # The maximum age of a batch before it is flushed.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    timeout_secs = 1

  #
  # Buffer
  #

  [sinks.elasticsearch.buffer]
    # The maximum number of events allowed in the buffer.
    #
    # * optional
    # * default: 500
    # * type: uint
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * required
    # * type: uint
    # * unit: bytes
    # * required when type = "disk"
    max_size = 104900000

    # The buffer's type and storage mechanism.
    #
    # * optional
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # General
  #

  # The compression strategy used to compress the encoded event data before
  # transmission.
  #
  # * optional
  # * default: "none"
  # * type: string
  # * enum: "none" or "gzip"
  compression = "none"
  compression = "gzip"

  # The `doc_type` for your index data. This is only relevant for Elasticsearch
  # <= 6.X. If you are using >= 7.0 you do not need to set this option since
  # Elasticsearch has removed it.
  #
  # * optional
  # * default: "_doc"
  # * type: string
  doc_type = "_doc"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # The host of your Elasticsearch cluster. This should be the full URL as shown
  # in the example.
  #
  # * optional
  # * no default
  # * type: string
  host = "http://10.24.32.122:9000"

  # The name of the event key that should map to Elasticsearch's `_id` field. By
  # default, Vector does not set the `_id` field, which allows Elasticsearch to
  # set this automatically. You should think carefully about setting your own
  # Elasticsearch IDs, since this can hinder perofrmance.
  #
  # * optional
  # * no default
  # * type: string
  id_key = "id"
  id_key = "_id"

  # Index name to write events to.
  #
  # * optional
  # * default: "vector-%F"
  # * type: string
  index = "application-{{ application_id }}-%Y-%m-%d"
  index = "vector-%Y-%m-%d"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # Name of the pipeline to apply.
  #
  # * optional
  # * no default
  # * type: string
  pipeline = "pipeline-name"

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "elasticsearch"
  type = "elasticsearch"

  #
  # Encoding
  #

  [sinks.elasticsearch.encoding]
    # Prevent the sink from encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    except_fields = ["timestamp", "message", "host"]

    # Limit the sink to only encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    only_fields = ["timestamp", "message", "host"]

    # How to format event timestamps.
    #
    # * optional
    # * default: "rfc3339"
    # * type: string
    # * enum: "rfc3339" or "unix"
    timestamp_format = "rfc3339"
    timestamp_format = "unix"

  #
  # Headers
  #

  [sinks.elasticsearch.headers]
    # A custom header to be added to each outgoing Elasticsearch request.
    #
    # * required
    # * type: string
    Authorization = "${ELASTICSEARCH_TOKEN}"
    X-Powered-By = "Vector"

  #
  # Query
  #

  [sinks.elasticsearch.query]
    # A custom parameter to be added to each Elasticsearch request.
    #
    # * required
    # * type: string
    X-Powered-By = "Vector"

  #
  # Request
  #

  [sinks.elasticsearch.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 5
    # * type: uint
    # * unit: requests
    in_flight_limit = 5

    # The time window, in seconds, used for the `rate_limit_num` option.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # time window.
    #
    # * optional
    # * default: 5
    # * type: uint
    rate_limit_num = 5

    # The maximum number of retries to make for failed requests. The default, for
    # all intents and purposes, represents an infinite number of retries.
    #
    # * optional
    # * default: 18446744073709551615
    # * type: uint
    retry_attempts = 18446744073709551615

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time, in seconds, to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: uint
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 60
    # * type: uint
    # * unit: seconds
    timeout_secs = 60

  #
  # TLS
  #

  [sinks.elasticsearch.tls]
    # Absolute path to an additional CA certificate file, in DER or PEM format
    # (X.509), or an inline CA certificate in PEM format.
    #
    # * optional
    # * no default
    # * type: string
    ca_file = "/path/to/certificate_authority.crt"

    # Absolute path to a certificate file used to identify this connection, in DER
    # or PEM format (X.509) or PKCS#12, or an inline certificate in PEM format. If
    # this is set and is not a PKCS#12 archive, `key_file` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    crt_file = "/path/to/host_certificate.crt"

    # Absolute path to a private key file used to identify this connection, in DER
    # or PEM format (PKCS#8), or an inline private key in PEM format. If this is
    # set, `crt_file` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    key_file = "/path/to/host_certificate.key"

    # Pass phrase used to unlock the encrypted key file. This has no effect unless
    # `key_file` is set.
    #
    # * optional
    # * no default
    # * type: string
    key_pass = "${KEY_PASS_ENV_VAR}"
    key_pass = "PassWord1"

    # If `true` (the default), Vector will validate the TLS certificate of the
    # remote host.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_certificate = true
    verify_certificate = false

    # If `true` (the default), Vector will validate the configured remote host name
    # against the remote host's TLS certificate. Do NOT set this to `false` unless
    # you understand the risks of not verifying the remote hostname.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_hostname = true
    verify_hostname = false

# Streams `log` events to a file.
[sinks.file]
  #
  # Encoding
  #

  [sinks.file.encoding]
    # The encoding codec used to serialize the events before outputting.
    #
    # * required
    # * type: string
    # * enum: "ndjson" or "text"
    codec = "ndjson"
    codec = "text"

    # Prevent the sink from encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    except_fields = ["timestamp", "message", "host"]

    # Limit the sink to only encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    only_fields = ["timestamp", "message", "host"]

    # How to format event timestamps.
    #
    # * optional
    # * default: "rfc3339"
    # * type: string
    # * enum: "rfc3339" or "unix"
    timestamp_format = "rfc3339"
    timestamp_format = "unix"

  #
  # General
  #

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # The amount of time a file can be idle  and stay open. After not receiving any
  # events for this timeout, the file will be flushed and closed.
  #
  # * optional
  # * default: "30"
  # * type: uint
  idle_timeout_secs = "30"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # File name to write events to.
  #
  # * required
  # * type: string
  path = "vector-%Y-%m-%d.log"
  path = "application-{{ application_id }}-%Y-%m-%d.log"

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "file"
  type = "file"

# Batches `log` events to Google Cloud Platform's Cloud Storage service via the XML Interface.
[sinks.gcp_cloud_storage]
  #
  # Object Attributes
  #

  # Predefined ACL to apply to the created objects. For more information, see
  # Predefined ACLs. If this is not set, GCS will apply a default ACL when the
  # object is created.
  #
  # * optional
  # * no default
  # * type: string
  # * enum: "authenticatedRead", "bucketOwnerFullControl", "bucketOwnerRead", "private", "projectPrivate", and "publicRead"
  acl = "authenticatedRead"
  acl = "bucketOwnerFullControl"
  acl = "bucketOwnerRead"
  acl = "private"
  acl = "projectPrivate"
  acl = "publicRead"

  # The set of metadata `key:value` pairs for the created objects. See the GCS
  # custom metadata documentation for more details.
  #
  # * optional
  # * no default
  # * type: string

  # The storage class for the created objects. See the GCP storage classes for
  # more details.
  #
  # * optional
  # * no default
  # * type: string
  # * enum: "STANDARD", "NEARLINE", "COLDLINE", and "ARCHIVE"
  storage_class = "STANDARD"
  storage_class = "NEARLINE"
  storage_class = "COLDLINE"
  storage_class = "ARCHIVE"

  #
  # Batch
  #

  [sinks.gcp_cloud_storage.batch]
    # The maximum size of a batch, in bytes, before it is flushed.
    #
    # * optional
    # * default: 10485760
    # * type: uint
    # * unit: bytes
    max_bytes = 10485760

    # The maximum size of a batch, in events, before it is flushed.
    #
    # * optional
    # * no default
    # * type: uint
    # * unit: events
    max_events = 1000

    # The maximum age of a batch before it is flushed.
    #
    # * optional
    # * default: 300
    # * type: uint
    # * unit: seconds
    timeout_secs = 300

  #
  # General
  #

  # The GCS bucket name.
  #
  # * required
  # * type: string
  bucket = "my-bucket"

  # The compression strategy used to compress the encoded event data before
  # transmission.
  #
  # * optional
  # * default: "none"
  # * type: string
  # * enum: "none" or "gzip"
  compression = "none"
  compression = "gzip"

  # The filename for a Google Cloud service account credentials JSON file used to
  # authenticate access to the Cloud Storage API. If this is unset, Vector checks
  # the `GOOGLE_APPLICATION_CREDENTIALS` environment variable for a filename.
  #
  # If no filename is named, Vector will attempt to fetch an instance service
  # account for the compute instance the program is running on. If Vector is not
  # running on a GCE instance, you must define a credentials file as above.
  #
  # * optional
  # * no default
  # * type: string
  credentials_path = "/path/to/credentials.json"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "gcp_cloud_storage"
  type = "gcp_cloud_storage"

  #
  # Buffer
  #

  [sinks.gcp_cloud_storage.buffer]
    # The maximum number of events allowed in the buffer.
    #
    # * optional
    # * default: 500
    # * type: uint
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * required
    # * type: uint
    # * unit: bytes
    # * required when type = "disk"
    max_size = 104900000

    # The buffer's type and storage mechanism.
    #
    # * optional
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Encoding
  #

  [sinks.gcp_cloud_storage.encoding]
    # The encoding codec used to serialize the events before outputting.
    #
    # * required
    # * type: string
    # * enum: "ndjson" or "text"
    codec = "ndjson"
    codec = "text"

    # Prevent the sink from encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    except_fields = ["timestamp", "message", "host"]

    # Limit the sink to only encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    only_fields = ["timestamp", "message", "host"]

    # How to format event timestamps.
    #
    # * optional
    # * default: "rfc3339"
    # * type: string
    # * enum: "rfc3339" or "unix"
    timestamp_format = "rfc3339"
    timestamp_format = "unix"

  #
  # Object Names
  #

  # Whether or not to append a UUID v4 token to the end of the file. This ensures
  # there are no name collisions high volume use cases.
  #
  # * optional
  # * default: true
  # * type: bool
  filename_append_uuid = true
  filename_append_uuid = false

  # The filename extension to use in the object name.
  #
  # * optional
  # * default: "log"
  # * type: string
  filename_extension = "log"

  # The format of the resulting object file name. `strftime` specifiers are
  # supported.
  #
  # * optional
  # * default: "%s"
  # * type: string
  filename_time_format = "%s"

  # A prefix to apply to all object key names. This should be used to partition
  # your objects, and it's important to end this value with a `/` if you want
  # this to be the root GCS "folder".
  #
  # * optional
  # * default: "date=%F/"
  # * type: string
  key_prefix = "date=%F/"
  key_prefix = "date=%F/hour=%H/"
  key_prefix = "year=%Y/month=%m/day=%d/"
  key_prefix = "application_id={{ application_id }}/date=%F/"

  #
  # Request
  #

  [sinks.gcp_cloud_storage.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 5
    # * type: uint
    # * unit: requests
    in_flight_limit = 5

    # The time window, in seconds, used for the `rate_limit_num` option.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # time window.
    #
    # * optional
    # * default: 1000
    # * type: uint
    rate_limit_num = 1000

    # The maximum number of retries to make for failed requests. The default, for
    # all intents and purposes, represents an infinite number of retries.
    #
    # * optional
    # * default: 18446744073709551615
    # * type: uint
    retry_attempts = 18446744073709551615

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time, in seconds, to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: uint
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 60
    # * type: uint
    # * unit: seconds
    timeout_secs = 60

  #
  # TLS
  #

  [sinks.gcp_cloud_storage.tls]
    # Absolute path to an additional CA certificate file, in DER or PEM format
    # (X.509), or an inline CA certificate in PEM format.
    #
    # * optional
    # * no default
    # * type: string
    ca_file = "/path/to/certificate_authority.crt"

    # Absolute path to a certificate file used to identify this connection, in DER
    # or PEM format (X.509) or PKCS#12, or an inline certificate in PEM format. If
    # this is set and is not a PKCS#12 archive, `key_file` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    crt_file = "/path/to/host_certificate.crt"

    # Absolute path to a private key file used to identify this connection, in DER
    # or PEM format (PKCS#8), or an inline private key in PEM format. If this is
    # set, `crt_file` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    key_file = "/path/to/host_certificate.key"

    # Pass phrase used to unlock the encrypted key file. This has no effect unless
    # `key_file` is set.
    #
    # * optional
    # * no default
    # * type: string
    key_pass = "${KEY_PASS_ENV_VAR}"
    key_pass = "PassWord1"

    # If `true` (the default), Vector will validate the TLS certificate of the
    # remote host.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_certificate = true
    verify_certificate = false

    # If `true` (the default), Vector will validate the configured remote host name
    # against the remote host's TLS certificate. Do NOT set this to `false` unless
    # you understand the risks of not verifying the remote hostname.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_hostname = true
    verify_hostname = false

# Batches `log` events to Google Cloud Platform's Pubsub service via the REST Interface.
[sinks.gcp_pubsub]
  #
  # General
  #

  # A Google Cloud API key used to authenticate access the pubsub project and
  # topic. Either this or `credentials_path` must be set.
  #
  # * optional
  # * no default
  # * type: string
  api_key = "${GCP_API_KEY}"
  api_key = "ef8d5de700e7989468166c40fc8a0ccd"

  # The filename for a Google Cloud service account credentials JSON file used to
  # authenticate access to the pubsub project and topic. If this is unset, Vector
  # checks the `GOOGLE_APPLICATION_CREDENTIALS` environment variable for a
  # filename.
  #
  # If no filename is named, Vector will attempt to fetch an instance service
  # account for the compute instance the program is running on. If Vector is not
  # running on a GCE instance, you must define a credentials file as above.
  #
  # * optional
  # * no default
  # * type: string
  credentials_path = "/path/to/credentials.json"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # The project name to which to publish logs.
  #
  # * required
  # * type: string
  project = "vector-123456"

  # The topic within the project to which to publish logs.
  #
  # * required
  # * type: string
  topic = "this-is-a-topic"

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "gcp_pubsub"
  type = "gcp_pubsub"

  #
  # Batch
  #

  [sinks.gcp_pubsub.batch]
    # The maximum size of a batch, in bytes, before it is flushed.
    #
    # * optional
    # * default: 10485760
    # * type: uint
    # * unit: bytes
    max_bytes = 10485760

    # The maximum size of a batch, in events, before it is flushed.
    #
    # * optional
    # * default: 1000
    # * type: uint
    # * unit: events
    max_events = 1000

    # The maximum age of a batch before it is flushed.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    timeout_secs = 1

  #
  # Buffer
  #

  [sinks.gcp_pubsub.buffer]
    # The maximum number of events allowed in the buffer.
    #
    # * optional
    # * default: 500
    # * type: uint
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * required
    # * type: uint
    # * unit: bytes
    # * required when type = "disk"
    max_size = 104900000

    # The buffer's type and storage mechanism.
    #
    # * optional
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Encoding
  #

  [sinks.gcp_pubsub.encoding]
    # Prevent the sink from encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    except_fields = ["timestamp", "message", "host"]

    # Limit the sink to only encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    only_fields = ["timestamp", "message", "host"]

    # How to format event timestamps.
    #
    # * optional
    # * default: "rfc3339"
    # * type: string
    # * enum: "rfc3339" or "unix"
    timestamp_format = "rfc3339"
    timestamp_format = "unix"

  #
  # Request
  #

  [sinks.gcp_pubsub.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 5
    # * type: uint
    # * unit: requests
    in_flight_limit = 5

    # The time window, in seconds, used for the `rate_limit_num` option.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # time window.
    #
    # * optional
    # * default: 100
    # * type: uint
    rate_limit_num = 100

    # The maximum number of retries to make for failed requests. The default, for
    # all intents and purposes, represents an infinite number of retries.
    #
    # * optional
    # * default: 18446744073709551615
    # * type: uint
    retry_attempts = 18446744073709551615

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time, in seconds, to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: uint
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 60
    # * type: uint
    # * unit: seconds
    timeout_secs = 60

  #
  # TLS
  #

  [sinks.gcp_pubsub.tls]
    # Absolute path to an additional CA certificate file, in DER or PEM format
    # (X.509), or an inline CA certificate in PEM format.
    #
    # * optional
    # * no default
    # * type: string
    ca_file = "/path/to/certificate_authority.crt"

    # Absolute path to a certificate file used to identify this connection, in DER
    # or PEM format (X.509) or PKCS#12, or an inline certificate in PEM format. If
    # this is set and is not a PKCS#12 archive, `key_file` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    crt_file = "/path/to/host_certificate.crt"

    # Absolute path to a private key file used to identify this connection, in DER
    # or PEM format (PKCS#8), or an inline private key in PEM format. If this is
    # set, `crt_file` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    key_file = "/path/to/host_certificate.key"

    # Pass phrase used to unlock the encrypted key file. This has no effect unless
    # `key_file` is set.
    #
    # * optional
    # * no default
    # * type: string
    key_pass = "${KEY_PASS_ENV_VAR}"
    key_pass = "PassWord1"

    # If `true` (the default), Vector will validate the TLS certificate of the
    # remote host.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_certificate = true
    verify_certificate = false

    # If `true` (the default), Vector will validate the configured remote host name
    # against the remote host's TLS certificate. Do NOT set this to `false` unless
    # you understand the risks of not verifying the remote hostname.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_hostname = true
    verify_hostname = false

# Batches `log` events to Google Cloud Platform's Stackdriver Logging service via the REST Interface.
[sinks.gcp_stackdriver_logs]
  #
  # Batch
  #

  [sinks.gcp_stackdriver_logs.batch]
    # The maximum size of a batch, in bytes, before it is flushed.
    #
    # * optional
    # * default: 5242880
    # * type: uint
    # * unit: bytes
    max_bytes = 5242880

    # The maximum size of a batch, in events, before it is flushed.
    #
    # * optional
    # * no default
    # * type: uint
    # * unit: events
    max_events = 1000

    # The maximum age of a batch before it is flushed.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    timeout_secs = 1

  #
  # General
  #

  # The billing account ID to which to publish logs.
  #
  # Exactly one of `billing_account_id`, `folder_id`, `organization_id`, or
  # `project_id` must be set.
  #
  # * optional
  # * no default
  # * type: string
  billing_account_id = "012345-6789AB-CDEF01"

  # The filename for a Google Cloud service account credentials JSON file used to
  # authenticate access to the Stackdriver Logging API. If this is unset, Vector
  # checks the `GOOGLE_APPLICATION_CREDENTIALS` environment variable for a
  # filename.
  #
  # If no filename is named, Vector will attempt to fetch an instance service
  # account for the compute instance the program is running on. If Vector is not
  # running on a GCE instance, you must define a credentials file as above.
  #
  # * optional
  # * no default
  # * type: string
  credentials_path = "/path/to/credentials.json"

  # The folder ID to which to publish logs.
  # See the Google Cloud Platform folder documentation for more details.
  #
  # Exactly one of `billing_account_id`, `folder_id`, `organization_id`, or
  # `project_id` must be set.
  #
  # * optional
  # * no default
  # * type: string
  folder_id = "My Folder"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # The log ID to which to publish logs. This is a name you create to identify
  # this log stream.
  #
  # * required
  # * type: string
  log_id = "vector-logs"

  # The organization ID to which to publish logs. This would be the identifier
  # assigned to your organization on Google Cloud Platform.
  #
  # Exactly one of `billing_account_id`, `folder_id`, `organization_id`, or
  # `project_id` must be set.
  #
  # * optional
  # * no default
  # * type: string
  organization_id = "622418129737"

  # The project ID to which to publish logs. See the Google Cloud Platform
  # project management documentation for more details.
  #
  # Exactly one of `billing_account_id`, `folder_id`, `organization_id`, or
  # `project_id` must be set.
  #
  # * required
  # * type: string
  project_id = "vector-123456"

  # The field of the log event from which to take the outgoing log's `severity`
  # field. The named field is removed from the log event if present, and must be
  # either an integer between 0 and 800 or a string containing one of the
  # severity level names (case is ignored) or a common prefix such as `err`. This
  # could be added by an `add_fields` transform or extracted from a field from
  # the source.
  #
  # If no severity key is specified, the severity of outgoing records will be set
  # to 0 (`DEFAULT`).
  #
  # See the GCP Stackdriver Logging LogSeverity description for more details on
  # the value of the `severity` field.
  #
  # * optional
  # * no default
  # * type: string
  severity_key = "severity"

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "gcp_stackdriver_logs"
  type = "gcp_stackdriver_logs"

  #
  # Buffer
  #

  [sinks.gcp_stackdriver_logs.buffer]
    # The maximum number of events allowed in the buffer.
    #
    # * optional
    # * default: 500
    # * type: uint
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * required
    # * type: uint
    # * unit: bytes
    # * required when type = "disk"
    max_size = 104900000

    # The buffer's type and storage mechanism.
    #
    # * optional
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Encoding
  #

  [sinks.gcp_stackdriver_logs.encoding]
    # Prevent the sink from encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    except_fields = ["timestamp", "message", "host"]

    # Limit the sink to only encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    only_fields = ["timestamp", "message", "host"]

    # How to format event timestamps.
    #
    # * optional
    # * default: "rfc3339"
    # * type: string
    # * enum: "rfc3339" or "unix"
    timestamp_format = "rfc3339"
    timestamp_format = "unix"

  #
  # Request
  #

  [sinks.gcp_stackdriver_logs.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 5
    # * type: uint
    # * unit: requests
    in_flight_limit = 5

    # The time window, in seconds, used for the `rate_limit_num` option.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # time window.
    #
    # * optional
    # * default: 1000
    # * type: uint
    rate_limit_num = 1000

    # The maximum number of retries to make for failed requests. The default, for
    # all intents and purposes, represents an infinite number of retries.
    #
    # * optional
    # * default: 18446744073709551615
    # * type: uint
    retry_attempts = 18446744073709551615

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time, in seconds, to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: uint
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 60
    # * type: uint
    # * unit: seconds
    timeout_secs = 60

  #
  # Resource
  #

  [sinks.gcp_stackdriver_logs.resource]
    # The monitored resource type. For example, the type of a Compute Engine VM
    # instance is gce_instance.
    #
    # See the Google Cloud Platform monitored resource documentation for more
    # details.
    #
    # * required
    # * type: string
    type = "global"
    type = "gce_instance"

    # Values for all of the labels listed in the associated monitored resource
    # descriptor.
    #
    # For example, Compute Engine VM instances use the labels `projectId`,
    # `instanceId`, and `zone`.
    #
    # * optional
    # * no default
    # * type: string
    projectId = "vector-123456"
    zone = "Twilight"

  #
  # TLS
  #

  [sinks.gcp_stackdriver_logs.tls]
    # Absolute path to an additional CA certificate file, in DER or PEM format
    # (X.509), or an inline CA certificate in PEM format.
    #
    # * optional
    # * no default
    # * type: string
    ca_file = "/path/to/certificate_authority.crt"

    # Absolute path to a certificate file used to identify this connection, in DER
    # or PEM format (X.509) or PKCS#12, or an inline certificate in PEM format. If
    # this is set and is not a PKCS#12 archive, `key_file` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    crt_file = "/path/to/host_certificate.crt"

    # Absolute path to a private key file used to identify this connection, in DER
    # or PEM format (PKCS#8), or an inline private key in PEM format. If this is
    # set, `crt_file` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    key_file = "/path/to/host_certificate.key"

    # Pass phrase used to unlock the encrypted key file. This has no effect unless
    # `key_file` is set.
    #
    # * optional
    # * no default
    # * type: string
    key_pass = "${KEY_PASS_ENV_VAR}"
    key_pass = "PassWord1"

    # If `true` (the default), Vector will validate the TLS certificate of the
    # remote host.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_certificate = true
    verify_certificate = false

    # If `true` (the default), Vector will validate the configured remote host name
    # against the remote host's TLS certificate. Do NOT set this to `false` unless
    # you understand the risks of not verifying the remote hostname.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_hostname = true
    verify_hostname = false

# Batches `log` events to Honeycomb via the batch events API.
[sinks.honeycomb]
  #
  # General
  #

  # The team key that will be used to authenticate against Honeycomb.
  #
  # * required
  # * type: string
  api_key = "${HONEYCOMB_API_KEY}"
  api_key = "some-api-key"

  # The dataset that Vector will send logs to.
  #
  # * required
  # * type: string
  dataset = "my-honeycomb-dataset"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "honeycomb"
  type = "honeycomb"

  #
  # Batch
  #

  [sinks.honeycomb.batch]
    # The maximum size of a batch, in bytes, before it is flushed.
    #
    # * optional
    # * default: 5242880
    # * type: uint
    # * unit: bytes
    max_bytes = 5242880

    # The maximum size of a batch, in events, before it is flushed.
    #
    # * optional
    # * no default
    # * type: uint
    # * unit: events
    max_events = 1000

    # The maximum age of a batch before it is flushed.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    timeout_secs = 1

  #
  # Buffer
  #

  [sinks.honeycomb.buffer]
    # The maximum number of events allowed in the buffer.
    #
    # * optional
    # * default: 500
    # * type: uint
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * required
    # * type: uint
    # * unit: bytes
    # * required when type = "disk"
    max_size = 104900000

    # The buffer's type and storage mechanism.
    #
    # * optional
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Request
  #

  [sinks.honeycomb.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 5
    # * type: uint
    # * unit: requests
    in_flight_limit = 5

    # The time window, in seconds, used for the `rate_limit_num` option.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # time window.
    #
    # * optional
    # * default: 5
    # * type: uint
    rate_limit_num = 5

    # The maximum number of retries to make for failed requests. The default, for
    # all intents and purposes, represents an infinite number of retries.
    #
    # * optional
    # * default: 18446744073709551615
    # * type: uint
    retry_attempts = 18446744073709551615

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time, in seconds, to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: uint
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 60
    # * type: uint
    # * unit: seconds
    timeout_secs = 60

# Batches `log` events to a generic HTTP endpoint.
[sinks.http]
  #
  # Auth
  #

  [sinks.http.auth]
    # The basic authentication password.
    #
    # * required
    # * type: string
    # * required when strategy = "basic"
    password = "${HTTP_PASSWORD}"
    password = "password"

    # The authentication strategy to use.
    #
    # * required
    # * type: string
    # * enum: "basic" or "bearer"
    strategy = "basic"
    strategy = "bearer"

    # The token to use for bearer authentication
    #
    # * required
    # * type: string
    # * required when strategy = "bearer"
    token = "${API_TOKEN}"
    token = "xyz123"

    # The basic authentication user name.
    #
    # * required
    # * type: string
    # * required when strategy = "basic"
    user = "${HTTP_USERNAME}"
    user = "username"

  #
  # Batch
  #

  [sinks.http.batch]
    # The maximum size of a batch, in bytes, before it is flushed.
    #
    # * optional
    # * default: 1049000
    # * type: uint
    # * unit: bytes
    max_bytes = 1049000

    # The maximum size of a batch, in events, before it is flushed.
    #
    # * optional
    # * no default
    # * type: uint
    # * unit: events
    max_events = 1000

    # The maximum age of a batch before it is flushed.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    timeout_secs = 1

  #
  # Buffer
  #

  [sinks.http.buffer]
    # The maximum number of events allowed in the buffer.
    #
    # * optional
    # * default: 500
    # * type: uint
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * required
    # * type: uint
    # * unit: bytes
    # * required when type = "disk"
    max_size = 104900000

    # The buffer's type and storage mechanism.
    #
    # * optional
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # General
  #

  # The compression strategy used to compress the encoded event data before
  # transmission.
  #
  # * optional
  # * default: "none"
  # * type: string
  # * enum: "none" or "gzip"
  compression = "none"
  compression = "gzip"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # A URI that Vector can request in order to determine the service health.
  #
  # * optional
  # * no default
  # * type: string
  healthcheck_uri = "https://10.22.212.22:9000/_health"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "http"
  type = "http"

  # The full URI to make HTTP requests to. This should include the protocol and
  # host, but can also include the port, path, and any other valid part of a URI.
  #
  # * required
  # * type: string
  uri = "https://10.22.212.22:9000/endpoint"

  #
  # Encoding
  #

  [sinks.http.encoding]
    # The encoding codec used to serialize the events before outputting.
    #
    # * required
    # * type: string
    # * enum: "json", "ndjson", and "text"
    codec = "json"
    codec = "ndjson"
    codec = "text"

    # Prevent the sink from encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    except_fields = ["timestamp", "message", "host"]

    # Limit the sink to only encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    only_fields = ["timestamp", "message", "host"]

    # How to format event timestamps.
    #
    # * optional
    # * default: "rfc3339"
    # * type: string
    # * enum: "rfc3339" or "unix"
    timestamp_format = "rfc3339"
    timestamp_format = "unix"

  #
  # Headers
  #

  [sinks.http.headers]
    # A custom header to be added to each outgoing HTTP request.
    #
    # * required
    # * type: string
    Authorization = "${HTTP_TOKEN}"
    X-Powered-By = "Vector"

  #
  # Request
  #

  [sinks.http.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 10
    # * type: uint
    # * unit: requests
    in_flight_limit = 10

    # The time window, in seconds, used for the `rate_limit_num` option.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # time window.
    #
    # * optional
    # * default: 1000
    # * type: uint
    rate_limit_num = 1000

    # The maximum number of retries to make for failed requests. The default, for
    # all intents and purposes, represents an infinite number of retries.
    #
    # * optional
    # * default: 18446744073709551615
    # * type: uint
    retry_attempts = 18446744073709551615

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time, in seconds, to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: uint
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 30
    # * type: uint
    # * unit: seconds
    timeout_secs = 30

  #
  # TLS
  #

  [sinks.http.tls]
    # Absolute path to an additional CA certificate file, in DER or PEM format
    # (X.509), or an inline CA certificate in PEM format.
    #
    # * optional
    # * no default
    # * type: string
    ca_file = "/path/to/certificate_authority.crt"

    # Absolute path to a certificate file used to identify this connection, in DER
    # or PEM format (X.509) or PKCS#12, or an inline certificate in PEM format. If
    # this is set and is not a PKCS#12 archive, `key_file` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    crt_file = "/path/to/host_certificate.crt"

    # Absolute path to a private key file used to identify this connection, in DER
    # or PEM format (PKCS#8), or an inline private key in PEM format. If this is
    # set, `crt_file` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    key_file = "/path/to/host_certificate.key"

    # Pass phrase used to unlock the encrypted key file. This has no effect unless
    # `key_file` is set.
    #
    # * optional
    # * no default
    # * type: string
    key_pass = "${KEY_PASS_ENV_VAR}"
    key_pass = "PassWord1"

    # If `true` (the default), Vector will validate the TLS certificate of the
    # remote host.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_certificate = true
    verify_certificate = false

    # If `true` (the default), Vector will validate the configured remote host name
    # against the remote host's TLS certificate. Do NOT set this to `false` unless
    # you understand the risks of not verifying the remote hostname.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_hostname = true
    verify_hostname = false

# Batches `log` events to Humio via the HEC API.
[sinks.humio_logs]
  #
  # Batch
  #

  [sinks.humio_logs.batch]
    # The maximum size of a batch, in bytes, before it is flushed.
    #
    # * optional
    # * default: 1049000
    # * type: uint
    # * unit: bytes
    max_bytes = 1049000

    # The maximum size of a batch, in events, before it is flushed.
    #
    # * optional
    # * no default
    # * type: uint
    # * unit: events
    max_events = 1000

    # The maximum age of a batch before it is flushed.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    timeout_secs = 1

  #
  # Buffer
  #

  [sinks.humio_logs.buffer]
    # The maximum number of events allowed in the buffer.
    #
    # * optional
    # * default: 500
    # * type: uint
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * required
    # * type: uint
    # * unit: bytes
    # * required when type = "disk"
    max_size = 104900000

    # The buffer's type and storage mechanism.
    #
    # * optional
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Requests
  #

  # The compression strategy used to compress the encoded event data before
  # transmission.
  #
  # * optional
  # * default: "none"
  # * type: string
  # * enum: "none" or "gzip"
  compression = "none"
  compression = "gzip"

  #
  # Encoding
  #

  [sinks.humio_logs.encoding]
    # The encoding codec used to serialize the events before outputting.
    #
    # * optional
    # * default: "json"
    # * type: string
    # * enum: "json" or "text"
    codec = "json"
    codec = "text"

    # Prevent the sink from encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    except_fields = ["timestamp", "message", "host"]

    # Limit the sink to only encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    only_fields = ["timestamp", "message", "host"]

    # How to format event timestamps.
    #
    # * optional
    # * default: "rfc3339"
    # * type: string
    # * enum: "rfc3339" or "unix"
    timestamp_format = "rfc3339"
    timestamp_format = "unix"

  #
  # General
  #

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # The optional host to send Humio logs to.
  #
  # * optional
  # * default: "https://cloud.humio.com"
  # * type: string
  host = "http://myhumiohost.com"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # Your Humio ingestion token.
  #
  # * required
  # * type: string
  token = "${HUMIO_TOKEN}"
  token = "A94A8FE5CCB19BA61C4C08"

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "humio_logs"
  type = "humio_logs"

  #
  # Request
  #

  [sinks.humio_logs.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 10
    # * type: uint
    # * unit: requests
    in_flight_limit = 10

    # The time window, in seconds, used for the `rate_limit_num` option.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # time window.
    #
    # * optional
    # * default: 10
    # * type: uint
    rate_limit_num = 10

    # The maximum number of retries to make for failed requests. The default, for
    # all intents and purposes, represents an infinite number of retries.
    #
    # * optional
    # * default: 18446744073709551615
    # * type: uint
    retry_attempts = 18446744073709551615

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time, in seconds, to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: uint
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 60
    # * type: uint
    # * unit: seconds
    timeout_secs = 60

# Batches `log` events to InfluxDB using v1 or v2 HTTP API.
[sinks.influxdb_logs]
  #
  # Batch
  #

  [sinks.influxdb_logs.batch]
    # The maximum size of a batch, in bytes, before it is flushed.
    #
    # * optional
    # * default: 1049000
    # * type: uint
    # * unit: bytes
    max_bytes = 1049000

    # The maximum size of a batch, in events, before it is flushed.
    #
    # * optional
    # * no default
    # * type: uint
    # * unit: events
    max_events = 1000

    # The maximum age of a batch before it is flushed.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    timeout_secs = 1

  #
  # General
  #

  # The destination bucket for writes into InfluxDB 2.
  #
  # * required
  # * type: string
  bucket = "vector-bucket"
  bucket = "4d2225e4d3d49f75"

  # Sets the target database for the write into InfluxDB 1.
  #
  # * required
  # * type: string
  database = "vector-database"
  database = "iot-store"

  # InfluxDB endpoint to send metrics to.
  #
  # * required
  # * type: string
  endpoint = "http://localhost:8086/"
  endpoint = "https://us-west-2-1.aws.cloud1.influxdata.com"
  endpoint = "https://us-west-2-1.aws.cloud2.influxdata.com"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # A prefix that will be added to all metric names.
  #
  # * required
  # * type: string
  namespace = "service"

  # A set of additional fields that will be attached to each LineProtocol as a
  # tag. Note: If the set of tag values has high cardinality this also increase
  # cardinality in InfluxDB.
  #
  # * optional
  # * no default
  # * type: [string]
  tags = ["field1", "parent.child_field"]

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "influxdb_logs"
  type = "influxdb_logs"

  #
  # Buffer
  #

  [sinks.influxdb_logs.buffer]
    # The maximum number of events allowed in the buffer.
    #
    # * optional
    # * default: 500
    # * type: uint
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * required
    # * type: uint
    # * unit: bytes
    # * required when type = "disk"
    max_size = 104900000

    # The buffer's type and storage mechanism.
    #
    # * optional
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Persistence
  #

  # Sets the write consistency for the point for InfluxDB 1.
  #
  # * optional
  # * no default
  # * type: string
  consistency = "any"
  consistency = "one"
  consistency = "quorum"
  consistency = "all"

  # Sets the target retention policy for the write into InfluxDB 1.
  #
  # * optional
  # * no default
  # * type: string
  retention_policy_name = "autogen"
  retention_policy_name = "one_day_only"

  #
  # Encoding
  #

  [sinks.influxdb_logs.encoding]
    # Prevent the sink from encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    except_fields = ["timestamp", "message", "host"]

    # Limit the sink to only encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    only_fields = ["timestamp", "message", "host"]

    # How to format event timestamps.
    #
    # * optional
    # * default: "rfc3339"
    # * type: string
    # * enum: "rfc3339" or "unix"
    timestamp_format = "rfc3339"
    timestamp_format = "unix"

  #
  # Auth
  #

  # Specifies the destination organization for writes into InfluxDB 2.
  #
  # * required
  # * type: string
  org = "my-org"
  org = "33f2cff0a28e5b63"

  # Sets the password for authentication if you’ve enabled authentication for the
  # write into InfluxDB 1.
  #
  # * optional
  # * no default
  # * type: string
  password = "${INFLUXDB_PASSWORD}"
  password = "influxdb4ever"

  # Authentication token for InfluxDB 2.
  #
  # * required
  # * type: string
  token = "${INFLUXDB_TOKEN}"
  token = "ef8d5de700e7989468166c40fc8a0ccd"

  # Sets the username for authentication if you’ve enabled authentication for the
  # write into InfluxDB 1.
  #
  # * optional
  # * no default
  # * type: string
  username = "todd"
  username = "vector-source"

  #
  # Request
  #

  [sinks.influxdb_logs.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 5
    # * type: uint
    # * unit: requests
    in_flight_limit = 5

    # The time window, in seconds, used for the `rate_limit_num` option.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # time window.
    #
    # * optional
    # * default: 5
    # * type: uint
    rate_limit_num = 5

    # The maximum number of retries to make for failed requests. The default, for
    # all intents and purposes, represents an infinite number of retries.
    #
    # * optional
    # * default: -1
    # * type: uint
    retry_attempts = -1

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time, in seconds, to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: uint
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 60
    # * type: uint
    # * unit: seconds
    timeout_secs = 60

# Batches `metric` events to InfluxDB using v1 or v2 HTTP API.
[sinks.influxdb_metrics]
  #
  # Batch
  #

  [sinks.influxdb_metrics.batch]
    # The maximum size of a batch, in events, before it is flushed.
    #
    # * optional
    # * default: 20
    # * type: uint
    # * unit: events
    max_events = 20

    # The maximum age of a batch before it is flushed.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    timeout_secs = 1

  #
  # General
  #

  # The destination bucket for writes into InfluxDB 2.
  #
  # * required
  # * type: string
  bucket = "vector-bucket"
  bucket = "4d2225e4d3d49f75"

  # Sets the target database for the write into InfluxDB 1.
  #
  # * required
  # * type: string
  database = "vector-database"
  database = "iot-store"

  # InfluxDB endpoint to send metrics to.
  #
  # * required
  # * type: string
  endpoint = "http://localhost:8086/"
  endpoint = "https://us-west-2-1.aws.cloud1.influxdata.com"
  endpoint = "https://us-west-2-1.aws.cloud2.influxdata.com"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # A prefix that will be added to all metric names.
  #
  # * required
  # * type: string
  namespace = "service"

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "influxdb_metrics"
  type = "influxdb_metrics"

  #
  # Persistence
  #

  # Sets the write consistency for the point for InfluxDB 1.
  #
  # * optional
  # * no default
  # * type: string
  consistency = "any"
  consistency = "one"
  consistency = "quorum"
  consistency = "all"

  # Sets the target retention policy for the write into InfluxDB 1.
  #
  # * optional
  # * no default
  # * type: string
  retention_policy_name = "autogen"
  retention_policy_name = "one_day_only"

  #
  # Auth
  #

  # Specifies the destination organization for writes into InfluxDB 2.
  #
  # * required
  # * type: string
  org = "my-org"
  org = "33f2cff0a28e5b63"

  # Sets the password for authentication if you’ve enabled authentication for the
  # write into InfluxDB 1.
  #
  # * optional
  # * no default
  # * type: string
  password = "${INFLUXDB_PASSWORD}"
  password = "influxdb4ever"

  # Authentication token for InfluxDB 2.
  #
  # * required
  # * type: string
  token = "${INFLUXDB_TOKEN}"
  token = "ef8d5de700e7989468166c40fc8a0ccd"

  # Sets the username for authentication if you’ve enabled authentication for the
  # write into InfluxDB 1.
  #
  # * optional
  # * no default
  # * type: string
  username = "todd"
  username = "vector-source"

  #
  # Request
  #

  [sinks.influxdb_metrics.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 5
    # * type: uint
    # * unit: requests
    in_flight_limit = 5

    # The time window, in seconds, used for the `rate_limit_num` option.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # time window.
    #
    # * optional
    # * default: 5
    # * type: uint
    rate_limit_num = 5

    # The maximum number of retries to make for failed requests. The default, for
    # all intents and purposes, represents an infinite number of retries.
    #
    # * optional
    # * default: 18446744073709551615
    # * type: uint
    retry_attempts = 18446744073709551615

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time, in seconds, to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: uint
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 60
    # * type: uint
    # * unit: seconds
    timeout_secs = 60

# Streams `log` events to Apache Kafka via the Kafka protocol.
[sinks.kafka]
  #
  # General
  #

  # A comma-separated list of host and port pairs that are the addresses of the
  # Kafka brokers in a "bootstrap" Kafka cluster that a Kafka client connects to
  # initially to bootstrap itself.
  #
  # * required
  # * type: string
  bootstrap_servers = "10.14.22.123:9092,10.14.23.332:9092"

  # The compression strategy used to compress the encoded event data before
  # transmission.
  #
  # * optional
  # * default: "none"
  # * type: string
  # * enum: "none", "gzip", "lz4", "snappy", and "zstd"
  compression = "none"
  compression = "gzip"
  compression = "lz4"
  compression = "snappy"
  compression = "zstd"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # The log field name to use for the topic key. If unspecified, the key will be
  # randomly generated. If the field does not exist on the log, a blank value
  # will be used.
  #
  # * required
  # * type: string
  key_field = "user_id"

  # Local message timeout.
  #
  # * optional
  # * default: 300000
  # * type: uint
  message_timeout_ms = 150000
  message_timeout_ms = 450000

  # Default timeout for network requests.
  #
  # * optional
  # * default: 60000
  # * type: uint
  socket_timeout_ms = 30000
  socket_timeout_ms = 90000

  # The Kafka topic name to write events to.
  #
  # * required
  # * type: string
  topic = "topic-1234"
  topic = "logs-{{unit}}-%Y-%m-%d"

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "kafka"
  type = "kafka"

  #
  # Buffer
  #

  [sinks.kafka.buffer]
    # The maximum number of events allowed in the buffer.
    #
    # * optional
    # * default: 500
    # * type: uint
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * required
    # * type: uint
    # * unit: bytes
    # * required when type = "disk"
    max_size = 104900000

    # The buffer's type and storage mechanism.
    #
    # * optional
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Encoding
  #

  [sinks.kafka.encoding]
    # The encoding codec used to serialize the events before outputting.
    #
    # * optional
    # * default: "text"
    # * type: string
    # * enum: "json" or "text"
    codec = "json"
    codec = "text"

    # Prevent the sink from encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    except_fields = ["timestamp", "message", "host"]

    # Limit the sink to only encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    only_fields = ["timestamp", "message", "host"]

    # How to format event timestamps.
    #
    # * optional
    # * default: "rfc3339"
    # * type: string
    # * enum: "rfc3339" or "unix"
    timestamp_format = "rfc3339"
    timestamp_format = "unix"

  #
  # Advanced
  #

  [sinks.kafka.librdkafka_options]
    # The options and their values. Accepts `string` values.
    #
    # * optional
    # * no default
    # * type: string
    "client.id" = "${ENV_VAR}"
    "fetch.error.backoff.ms" = "1000"
    "socket.send.buffer.bytes" = "100"

  #
  # SASL
  #

  [sinks.kafka.sasl]
    # Enable SASL/SCRAM authentication to the remote. (Not supported on Windows at
    # this time.)
    #
    # * optional
    # * no default
    # * type: bool
    enabled = true
    enabled = false

    # The Kafka SASL/SCRAM mechanisms.
    #
    # * optional
    # * no default
    # * type: string
    mechanism = "SCRAM-SHA-256"
    mechanism = "SCRAM-SHA-512"

    # The Kafka SASL/SCRAM authentication password.
    #
    # * optional
    # * no default
    # * type: string
    password = "password"

    # The Kafka SASL/SCRAM authentication username.
    #
    # * optional
    # * no default
    # * type: string
    username = "username"

  #
  # TLS
  #

  [sinks.kafka.tls]
    # Absolute path to an additional CA certificate file, in DER or PEM format
    # (X.509), or an inline CA certificate in PEM format.
    #
    # * optional
    # * no default
    # * type: string
    ca_file = "/path/to/certificate_authority.crt"

    # Absolute path to a certificate file used to identify this connection, in DER
    # or PEM format (X.509) or PKCS#12, or an inline certificate in PEM format. If
    # this is set and is not a PKCS#12 archive, `key_file` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    crt_file = "/path/to/host_certificate.crt"

    # Enable TLS during connections to the remote.
    #
    # * optional
    # * default: false
    # * type: bool
    enabled = false
    enabled = true

    # Absolute path to a private key file used to identify this connection, in DER
    # or PEM format (PKCS#8), or an inline private key in PEM format. If this is
    # set, `crt_file` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    key_file = "/path/to/host_certificate.key"

    # Pass phrase used to unlock the encrypted key file. This has no effect unless
    # `key_file` is set.
    #
    # * optional
    # * no default
    # * type: string
    key_pass = "${KEY_PASS_ENV_VAR}"
    key_pass = "PassWord1"

# Batches `log` events to LogDna's HTTP Ingestion API.
[sinks.logdna]
  #
  # General
  #

  # The Ingestion API key.
  #
  # * required
  # * type: string
  api_key = "${LOGDNA_API_KEY}"
  api_key = "ef8d5de700e7989468166c40fc8a0ccd"

  # The default app that will be set for events that do not contain a `file` or
  # `app` field.
  #
  # * optional
  # * default: "vector"
  # * type: string
  default_app = "vector"
  default_app = "myapp"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # An optional host that will override the default one.
  #
  # * optional
  # * no default
  # * type: string
  host = "http://127.0.0.1"
  host = "http://example.com"

  # The hostname that will be attached to each batch of events.
  #
  # * required
  # * type: string
  hostname = "${HOSTNAME}"
  hostname = "my-local-machine"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # The IP address that will be attached to each batch of events.
  #
  # * optional
  # * no default
  # * type: string
  ip = "0.0.0.0"

  # The mac address that will be attached to each batch of events.
  #
  # * optional
  # * no default
  # * type: string
  mac = "my-mac-address"

  # The tags that will be attached to each batch of events.
  #
  # * optional
  # * no default
  # * type: [string]
  tags = ["tag1", "tag2"]

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "logdna"
  type = "logdna"

  #
  # Batch
  #

  [sinks.logdna.batch]
    # The maximum size of a batch, in bytes, before it is flushed.
    #
    # * optional
    # * default: 10490000
    # * type: uint
    # * unit: bytes
    max_bytes = 10490000

    # The maximum size of a batch, in events, before it is flushed.
    #
    # * optional
    # * no default
    # * type: uint
    # * unit: events
    max_events = 1000

    # The maximum age of a batch before it is flushed.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    timeout_secs = 1

  #
  # Buffer
  #

  [sinks.logdna.buffer]
    # The maximum number of events allowed in the buffer.
    #
    # * optional
    # * default: 500
    # * type: uint
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * required
    # * type: uint
    # * unit: bytes
    # * required when type = "disk"
    max_size = 104900000

    # The buffer's type and storage mechanism.
    #
    # * optional
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Encoding
  #

  [sinks.logdna.encoding]
    # Prevent the sink from encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    except_fields = ["timestamp", "message", "host"]

    # Limit the sink to only encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    only_fields = ["timestamp", "message", "host"]

    # How to format event timestamps.
    #
    # * optional
    # * default: "rfc3339"
    # * type: string
    # * enum: "rfc3339" or "unix"
    timestamp_format = "rfc3339"
    timestamp_format = "unix"

  #
  # Request
  #

  [sinks.logdna.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 5
    # * type: uint
    # * unit: requests
    in_flight_limit = 5

    # The time window, in seconds, used for the `rate_limit_num` option.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # time window.
    #
    # * optional
    # * default: 5
    # * type: uint
    rate_limit_num = 5

    # The maximum number of retries to make for failed requests. The default, for
    # all intents and purposes, represents an infinite number of retries.
    #
    # * optional
    # * default: 18446744073709551615
    # * type: uint
    retry_attempts = 18446744073709551615

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time, in seconds, to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: uint
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 60
    # * type: uint
    # * unit: seconds
    timeout_secs = 60

# Batches `log` events to Loki.
[sinks.loki]
  #
  # Auth
  #

  [sinks.loki.auth]
    # The basic authentication password. If using GrafanaLab's hosted Loki then
    # this must be set to your `instanceId`.
    #
    # * required
    # * type: string
    # * required when strategy = "basic"
    password = "${LOKI_PASSWORD}"
    password = "password"

    # The authentication strategy to use.
    #
    # * required
    # * type: string
    # * enum: "basic" or "bearer"
    strategy = "basic"
    strategy = "bearer"

    # The token to use for bearer authentication
    #
    # * required
    # * type: string
    # * required when strategy = "bearer"
    token = "${API_TOKEN}"
    token = "xyz123"

    # The basic authentication user name. If using GrafanaLab's hosted Loki then
    # this must be set to your Grafana.com api key.
    #
    # * required
    # * type: string
    # * required when strategy = "basic"
    user = "${LOKI_USERNAME}"
    user = "username"

  #
  # Batch
  #

  [sinks.loki.batch]
    # The maximum size of a batch, in events, before it is flushed.
    #
    # * optional
    # * default: 100000
    # * type: uint
    # * unit: events
    max_events = 100000

    # The maximum age of a batch before it is flushed.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    timeout_secs = 1

  #
  # Buffer
  #

  [sinks.loki.buffer]
    # The maximum number of events allowed in the buffer.
    #
    # * optional
    # * default: 500
    # * type: uint
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * required
    # * type: uint
    # * unit: bytes
    # * required when type = "disk"
    max_size = 104900000

    # The buffer's type and storage mechanism.
    #
    # * optional
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Encoding
  #

  [sinks.loki.encoding]
    # The encoding codec used to serialize the events before outputting.
    #
    # * optional
    # * default: "json"
    # * type: string
    # * enum: "json" or "text"
    codec = "json"
    codec = "text"

    # Prevent the sink from encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    except_fields = ["timestamp", "message", "host"]

    # Limit the sink to only encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    only_fields = ["timestamp", "message", "host"]

    # How to format event timestamps.
    #
    # * optional
    # * default: "rfc3339"
    # * type: string
    # * enum: "rfc3339" or "unix"
    timestamp_format = "rfc3339"
    timestamp_format = "unix"

  #
  # General
  #

  # The endpoint used to ship logs to.
  #
  # * required
  # * type: string
  endpoint = "http://localhost:3100"
  endpoint = "http://127.0.0.1:8080"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # If this is set to `true` then when labels are collected from events those
  # fields will also get removed from the event.
  #
  # * optional
  # * default: false
  # * type: bool
  remove_label_fields = false
  remove_label_fields = true

  # If this is set to `true` then the timestamp will be removed from the event.
  # This is useful because Loki uses the timestamp to index the event.
  #
  # * optional
  # * default: true
  # * type: bool
  remove_timestamp = true
  remove_timestamp = false

  # The tenant id that will be sent with every request, by default this is not
  # required since a proxy should set this header. When running Loki locally a
  # tenant id is not required either.
  #
  # You can read more about tenant id's here
  #
  # * optional
  # * no default
  # * type: string
  tenant_id = "some_tenant_id"

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "loki"
  type = "loki"

  #
  # Labels
  #

  [sinks.loki.labels]
    # A key-value pair for labels.
    #
    # * required
    # * type: string
    key = "value"
    key = "{{ event_field }}"

  #
  # Request
  #

  [sinks.loki.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 5
    # * type: uint
    # * unit: requests
    in_flight_limit = 5

    # The time window, in seconds, used for the `rate_limit_num` option.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # time window.
    #
    # * optional
    # * default: 5
    # * type: uint
    rate_limit_num = 5

    # The maximum number of retries to make for failed requests. The default, for
    # all intents and purposes, represents an infinite number of retries.
    #
    # * optional
    # * default: 18446744073709551615
    # * type: uint
    retry_attempts = 18446744073709551615

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time, in seconds, to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: uint
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 60
    # * type: uint
    # * unit: seconds
    timeout_secs = 60

  #
  # TLS
  #

  [sinks.loki.tls]
    # Absolute path to an additional CA certificate file, in DER or PEM format
    # (X.509), or an inline CA certificate in PEM format.
    #
    # * optional
    # * no default
    # * type: string
    ca_file = "/path/to/certificate_authority.crt"

    # Absolute path to a certificate file used to identify this connection, in DER
    # or PEM format (X.509) or PKCS#12, or an inline certificate in PEM format. If
    # this is set and is not a PKCS#12 archive, `key_file` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    crt_file = "/path/to/host_certificate.crt"

    # Absolute path to a private key file used to identify this connection, in DER
    # or PEM format (PKCS#8), or an inline private key in PEM format. If this is
    # set, `crt_file` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    key_file = "/path/to/host_certificate.key"

    # Pass phrase used to unlock the encrypted key file. This has no effect unless
    # `key_file` is set.
    #
    # * optional
    # * no default
    # * type: string
    key_pass = "${KEY_PASS_ENV_VAR}"
    key_pass = "PassWord1"

    # If `true` (the default), Vector will validate the TLS certificate of the
    # remote host.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_certificate = true
    verify_certificate = false

    # If `true` (the default), Vector will validate the configured remote host name
    # against the remote host's TLS certificate. Do NOT set this to `false` unless
    # you understand the risks of not verifying the remote hostname.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_hostname = true
    verify_hostname = false

# Batches `log` events to New Relic's log service via their log API.
[sinks.new_relic_logs]
  #
  # Batch
  #

  [sinks.new_relic_logs.batch]
    # The maximum size of a batch, in bytes, before it is flushed.
    #
    # * optional
    # * default: 5240000
    # * type: uint
    # * unit: bytes
    max_bytes = 5240000

    # The maximum size of a batch, in events, before it is flushed.
    #
    # * optional
    # * no default
    # * type: uint
    # * unit: events
    max_events = 1000

    # The maximum age of a batch before it is flushed.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    timeout_secs = 1

  #
  # Buffer
  #

  [sinks.new_relic_logs.buffer]
    # The maximum number of events allowed in the buffer.
    #
    # * optional
    # * default: 500
    # * type: uint
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * required
    # * type: uint
    # * unit: bytes
    # * required when type = "disk"
    max_size = 104900000

    # The buffer's type and storage mechanism.
    #
    # * optional
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Requests
  #

  # The compression strategy used to compress the encoded event data before
  # transmission.
  #
  # * optional
  # * default: "none"
  # * type: string
  # * enum: "none" or "gzip"
  compression = "none"
  compression = "gzip"

  #
  # Encoding
  #

  [sinks.new_relic_logs.encoding]
    # The encoding codec used to serialize the events before outputting.
    #
    # * optional
    # * default: "json"
    # * type: string
    # * must be: "json" (if supplied)
    codec = "json"

    # Prevent the sink from encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    except_fields = ["timestamp", "message", "host"]

    # Limit the sink to only encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    only_fields = ["timestamp", "message", "host"]

    # How to format event timestamps.
    #
    # * optional
    # * default: "rfc3339"
    # * type: string
    # * enum: "rfc3339" or "unix"
    timestamp_format = "rfc3339"
    timestamp_format = "unix"

  #
  # General
  #

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # Your New Relic insert key (if applicable).
  #
  # * optional
  # * no default
  # * type: string
  insert_key = "xxxx"
  insert_key = "${NEW_RELIC_INSERT_KEY}"

  # Your New Relic license key (if applicable).
  #
  # * optional
  # * no default
  # * type: string
  license_key = "xxxx"
  license_key = "${NEW_RELIC_LICENSE_KEY}"

  # The API region to send logs to.
  #
  # * optional
  # * default: "us"
  # * type: string
  # * enum: "us" or "eu"
  region = "us"
  region = "eu"

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "new_relic_logs"
  type = "new_relic_logs"

  #
  # Request
  #

  [sinks.new_relic_logs.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 5
    # * type: uint
    # * unit: requests
    in_flight_limit = 5

    # The time window, in seconds, used for the `rate_limit_num` option.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # time window.
    #
    # * optional
    # * default: 100
    # * type: uint
    rate_limit_num = 100

    # The maximum number of retries to make for failed requests. The default, for
    # all intents and purposes, represents an infinite number of retries.
    #
    # * optional
    # * default: 18446744073709551615
    # * type: uint
    retry_attempts = 18446744073709551615

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time, in seconds, to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: uint
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 30
    # * type: uint
    # * unit: seconds
    timeout_secs = 30

# Streams `log` events to Papertrail via Syslog.
[sinks.papertrail]
  #
  # Buffer
  #

  [sinks.papertrail.buffer]
    # The maximum number of events allowed in the buffer.
    #
    # * optional
    # * default: 500
    # * type: uint
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * required
    # * type: uint
    # * unit: bytes
    # * required when type = "disk"
    max_size = 104900000

    # The buffer's type and storage mechanism.
    #
    # * optional
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Encoding
  #

  [sinks.papertrail.encoding]
    # The encoding codec used to serialize the events before outputting.
    #
    # * required
    # * type: string
    # * enum: "json" or "text"
    codec = "json"
    codec = "text"

    # Prevent the sink from encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    except_fields = ["timestamp", "message", "host"]

    # Limit the sink to only encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    only_fields = ["timestamp", "message", "host"]

    # How to format event timestamps.
    #
    # * optional
    # * default: "rfc3339"
    # * type: string
    # * enum: "rfc3339" or "unix"
    timestamp_format = "rfc3339"
    timestamp_format = "unix"

  #
  # General
  #

  # The endpoint to stream logs to.
  #
  # * required
  # * type: string
  endpoint = "logs.papertrailapp.com:12345"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "papertrail"
  type = "papertrail"

# Exposes `metric` events to Prometheus metrics service.
[sinks.prometheus]
  # The address to expose for scraping.
  #
  # * required
  # * type: string
  address = "0.0.0.0:9598"

  # Default buckets to use for aggregating distribution metrics into histograms.
  #
  # * optional
  # * default: [0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0]
  # * type: [float]
  # * unit: seconds
  buckets = [0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0]

  # Time interval between set values are reset.
  #
  # * optional
  # * default: 60
  # * type: uint
  # * unit: seconds
  flush_period_secs = 60

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # A prefix that will be added to all metric names.
  # It should follow Prometheus naming conventions.
  #
  # * required
  # * type: string
  namespace = "service"

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "prometheus"
  type = "prometheus"

# Streams `log` events to Apache Pulsar via the Pulsar protocol.
[sinks.pulsar]
  #
  # General
  #

  # A host and port pair that the pulsar client should connect to.
  #
  # * required
  # * type: string
  address = "pulsar://127.0.0.1:6650"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # The Pulsar topic name to write events to.
  #
  # * required
  # * type: string
  topic = "topic-1234"

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "pulsar"
  type = "pulsar"

  #
  # Auth
  #

  [sinks.pulsar.auth]
    # The basic authentication name.
    #
    # * optional
    # * no default
    # * type: string
    name = "${PULSAR_NAME}"
    name = "name123"

    # The basic authentication password.
    #
    # * optional
    # * no default
    # * type: string
    token = "${PULSAR_TOKEN}"
    token = "123456789"

  #
  # Encoding
  #

  [sinks.pulsar.encoding]
    # The encoding codec used to serialize the events before outputting.
    #
    # * optional
    # * default: "text"
    # * type: string
    # * enum: "json" or "text"
    codec = "json"
    codec = "text"

    # Prevent the sink from encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    except_fields = ["timestamp", "message", "host"]

    # Limit the sink to only encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    only_fields = ["timestamp", "message", "host"]

    # How to format event timestamps.
    #
    # * optional
    # * default: "rfc3339"
    # * type: string
    # * enum: "rfc3339" or "unix"
    timestamp_format = "rfc3339"
    timestamp_format = "unix"

# Batches `log` events to Sematext via the Elasticsearch API.
[sinks.sematext_logs]
  #
  # Batch
  #

  [sinks.sematext_logs.batch]
    # The maximum size of a batch, in bytes, before it is flushed.
    #
    # * optional
    # * default: 10490000
    # * type: uint
    # * unit: bytes
    max_bytes = 10490000

    # The maximum size of a batch, in events, before it is flushed.
    #
    # * optional
    # * no default
    # * type: uint
    # * unit: events
    max_events = 1000

    # The maximum age of a batch before it is flushed.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    timeout_secs = 1

  #
  # Buffer
  #

  [sinks.sematext_logs.buffer]
    # The maximum number of events allowed in the buffer.
    #
    # * optional
    # * default: 500
    # * type: uint
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * required
    # * type: uint
    # * unit: bytes
    # * required when type = "disk"
    max_size = 104900000

    # The buffer's type and storage mechanism.
    #
    # * optional
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Encoding
  #

  [sinks.sematext_logs.encoding]
    # Prevent the sink from encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    except_fields = ["timestamp", "message", "host"]

    # Limit the sink to only encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    only_fields = ["timestamp", "message", "host"]

    # How to format event timestamps.
    #
    # * optional
    # * default: "rfc3339"
    # * type: string
    # * enum: "rfc3339" or "unix"
    timestamp_format = "rfc3339"
    timestamp_format = "unix"

  #
  # General
  #

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # The host that will be used to send logs to. This option is required if
  # `region` is not set.
  #
  # * optional
  # * no default
  # * type: string
  host = "http://127.0.0.1"
  host = "http://example.com"

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # The region destination to send logs to. This option is required if `host` is
  # not set.
  #
  # * optional
  # * no default
  # * type: string
  region = "na"
  region = "eu"

  # The token that will be used to write to Sematext.
  #
  # * required
  # * type: string
  token = "${SEMATEXT_TOKEN}"
  token = "some-sematext-token"

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "sematext_logs"
  type = "sematext_logs"

  #
  # Request
  #

  [sinks.sematext_logs.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 5
    # * type: uint
    # * unit: requests
    in_flight_limit = 5

    # The time window, in seconds, used for the `rate_limit_num` option.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # time window.
    #
    # * optional
    # * default: 5
    # * type: uint
    rate_limit_num = 5

    # The maximum number of retries to make for failed requests. The default, for
    # all intents and purposes, represents an infinite number of retries.
    #
    # * optional
    # * default: 18446744073709551615
    # * type: uint
    retry_attempts = 18446744073709551615

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time, in seconds, to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: uint
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 60
    # * type: uint
    # * unit: seconds
    timeout_secs = 60

# Streams `log` events to a socket, such as a TCP, UDP, or UDS socket.
[sinks.socket]
  #
  # General
  #

  # The address to connect to. The address _must_ include a port.
  #
  # * required
  # * type: string
  # * required when mode = "tcp" or mode = "udp"
  address = "92.12.333.224:5000"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # The type of socket to use.
  #
  # * required
  # * type: string
  # * enum: "tcp", "udp", and "unix"
  mode = "tcp"
  mode = "udp"
  mode = "unix"

  # The unix socket path. This should be the absolute path.
  #
  # * required
  # * type: string
  # * required when mode = "unix"
  path = "/path/to/socket"

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "socket"
  type = "socket"

  #
  # Buffer
  #

  [sinks.socket.buffer]
    # The maximum number of events allowed in the buffer.
    #
    # * optional
    # * default: 500
    # * type: uint
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * required
    # * type: uint
    # * unit: bytes
    # * required when type = "disk"
    max_size = 104900000

    # The buffer's type and storage mechanism.
    #
    # * optional
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Encoding
  #

  [sinks.socket.encoding]
    # The encoding codec used to serialize the events before outputting.
    #
    # * required
    # * type: string
    # * enum: "json" or "text"
    codec = "json"
    codec = "text"

    # Prevent the sink from encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    except_fields = ["timestamp", "message", "host"]

    # Limit the sink to only encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    only_fields = ["timestamp", "message", "host"]

    # How to format event timestamps.
    #
    # * optional
    # * default: "rfc3339"
    # * type: string
    # * enum: "rfc3339" or "unix"
    timestamp_format = "rfc3339"
    timestamp_format = "unix"

  #
  # TLS
  #

  [sinks.socket.tls]
    # Absolute path to an additional CA certificate file, in DER or PEM format
    # (X.509), or an inline CA certificate in PEM format.
    #
    # * optional
    # * no default
    # * type: string
    ca_file = "/path/to/certificate_authority.crt"

    # Absolute path to a certificate file used to identify this connection, in DER
    # or PEM format (X.509) or PKCS#12, or an inline certificate in PEM format. If
    # this is set and is not a PKCS#12 archive, `key_file` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    crt_file = "/path/to/host_certificate.crt"

    # Enable TLS during connections to the remote.
    #
    # * optional
    # * default: false
    # * type: bool
    enabled = false
    enabled = true

    # Absolute path to a private key file used to identify this connection, in DER
    # or PEM format (PKCS#8), or an inline private key in PEM format. If this is
    # set, `crt_file` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    key_file = "/path/to/host_certificate.key"

    # Pass phrase used to unlock the encrypted key file. This has no effect unless
    # `key_file` is set.
    #
    # * optional
    # * no default
    # * type: string
    key_pass = "${KEY_PASS_ENV_VAR}"
    key_pass = "PassWord1"

    # If `true` (the default), Vector will validate the TLS certificate of the
    # remote host.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_certificate = true
    verify_certificate = false

    # If `true` (the default), Vector will validate the configured remote host name
    # against the remote host's TLS certificate. Do NOT set this to `false` unless
    # you understand the risks of not verifying the remote hostname.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_hostname = true
    verify_hostname = false

# Batches `log` events to a Splunk's HTTP Event Collector.
[sinks.splunk_hec]
  #
  # Batch
  #

  [sinks.splunk_hec.batch]
    # The maximum size of a batch, in bytes, before it is flushed.
    #
    # * optional
    # * default: 1049000
    # * type: uint
    # * unit: bytes
    max_bytes = 1049000

    # The maximum size of a batch, in events, before it is flushed.
    #
    # * optional
    # * no default
    # * type: uint
    # * unit: events
    max_events = 1000

    # The maximum age of a batch before it is flushed.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    timeout_secs = 1

  #
  # Buffer
  #

  [sinks.splunk_hec.buffer]
    # The maximum number of events allowed in the buffer.
    #
    # * optional
    # * default: 500
    # * type: uint
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * required
    # * type: uint
    # * unit: bytes
    # * required when type = "disk"
    max_size = 104900000

    # The buffer's type and storage mechanism.
    #
    # * optional
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # Requests
  #

  # The compression strategy used to compress the encoded event data before
  # transmission.
  #
  # * optional
  # * default: "none"
  # * type: string
  # * enum: "none" or "gzip"
  compression = "none"
  compression = "gzip"

  #
  # Encoding
  #

  [sinks.splunk_hec.encoding]
    # The encoding codec used to serialize the events before outputting.
    #
    # * optional
    # * default: "text"
    # * type: string
    # * enum: "json" or "text"
    codec = "json"
    codec = "text"

    # Prevent the sink from encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    except_fields = ["timestamp", "message", "host"]

    # Limit the sink to only encoding the specified labels.
    #
    # * optional
    # * no default
    # * type: [string]
    only_fields = ["timestamp", "message", "host"]

    # How to format event timestamps.
    #
    # * optional
    # * default: "rfc3339"
    # * type: string
    # * enum: "rfc3339" or "unix"
    timestamp_format = "rfc3339"
    timestamp_format = "unix"

  #
  # General
  #

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # Your Splunk HEC host.
  #
  # * required
  # * type: string
  host = "http://my-splunk-host.com"

  # The name of the log field to be used as the hostname sent to Splunk HEC. This
  # overrides the global `host_key` option.
  #
  # * optional
  # * no default
  # * type: string
  host_key = "hostname"

  # The name of the index where send the events to. If not specified, the default
  # index is used.
  #
  # * optional
  # * no default
  # * type: string
  index = "custom_index"

  # Fields to be added to Splunk index.
  #
  # * optional
  # * no default
  # * type: [string]
  # * relevant when encoding = "json"
  indexed_fields = ["field1", "field2"]

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # Your Splunk HEC token.
  #
  # * required
  # * type: string
  token = "${SPLUNK_HEC_TOKEN}"
  token = "A94A8FE5CCB19BA61C4C08"

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "splunk_hec"
  type = "splunk_hec"

  #
  # Request
  #

  [sinks.splunk_hec.request]
    # The maximum number of in-flight requests allowed at any given time.
    #
    # * optional
    # * default: 10
    # * type: uint
    # * unit: requests
    in_flight_limit = 10

    # The time window, in seconds, used for the `rate_limit_num` option.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    rate_limit_duration_secs = 1

    # The maximum number of requests allowed within the `rate_limit_duration_secs`
    # time window.
    #
    # * optional
    # * default: 10
    # * type: uint
    rate_limit_num = 10

    # The maximum number of retries to make for failed requests. The default, for
    # all intents and purposes, represents an infinite number of retries.
    #
    # * optional
    # * default: 18446744073709551615
    # * type: uint
    retry_attempts = 18446744073709551615

    # The amount of time to wait before attempting the first retry for a failed
    # request. Once, the first retry has failed the fibonacci sequence will be used
    # to select future backoffs.
    #
    # * optional
    # * default: 1
    # * type: uint
    # * unit: seconds
    retry_initial_backoff_secs = 1

    # The maximum amount of time, in seconds, to wait between retries.
    #
    # * optional
    # * default: 10
    # * type: uint
    # * unit: seconds
    retry_max_duration_secs = 10

    # The maximum time a request can take before being aborted. It is highly
    # recommended that you do not lower value below the service's internal timeout,
    # as this could create orphaned requests, pile on retries, and result in
    # duplicate data downstream.
    #
    # * optional
    # * default: 60
    # * type: uint
    # * unit: seconds
    timeout_secs = 60

  #
  # TLS
  #

  [sinks.splunk_hec.tls]
    # Absolute path to an additional CA certificate file, in DER or PEM format
    # (X.509), or an inline CA certificate in PEM format.
    #
    # * optional
    # * no default
    # * type: string
    ca_file = "/path/to/certificate_authority.crt"

    # Absolute path to a certificate file used to identify this connection, in DER
    # or PEM format (X.509) or PKCS#12, or an inline certificate in PEM format. If
    # this is set and is not a PKCS#12 archive, `key_file` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    crt_file = "/path/to/host_certificate.crt"

    # Absolute path to a private key file used to identify this connection, in DER
    # or PEM format (PKCS#8), or an inline private key in PEM format. If this is
    # set, `crt_file` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    key_file = "/path/to/host_certificate.key"

    # Pass phrase used to unlock the encrypted key file. This has no effect unless
    # `key_file` is set.
    #
    # * optional
    # * no default
    # * type: string
    key_pass = "${KEY_PASS_ENV_VAR}"
    key_pass = "PassWord1"

    # If `true` (the default), Vector will validate the TLS certificate of the
    # remote host.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_certificate = true
    verify_certificate = false

    # If `true` (the default), Vector will validate the configured remote host name
    # against the remote host's TLS certificate. Do NOT set this to `false` unless
    # you understand the risks of not verifying the remote hostname.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_hostname = true
    verify_hostname = false

# Streams `metric` events to StatsD metrics service.
[sinks.statsd]
  # The UDP socket address to send stats to.
  #
  # * optional
  # * default: "127.0.0.1:8125"
  # * type: string
  address = "127.0.0.1:8125"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # A prefix that will be added to all metric names.
  #
  # * required
  # * type: string
  namespace = "service"

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "statsd"
  type = "statsd"

# Streams `log` and `metric` events to another downstream `vector` source.
[sinks.vector]
  #
  # General
  #

  # The downstream Vector address to connect to. The address _must_ include a
  # port.
  #
  # * required
  # * type: string
  address = "92.12.333.224:5000"

  # Enables/disables the sink healthcheck upon start.
  #
  # * optional
  # * default: true
  # * type: bool
  healthcheck = true
  healthcheck = false

  # A list of upstream source or transform IDs. See configuration for more info.
  #
  # * required
  # * type: [string]
  inputs = ["my-source-or-transform-id"]

  # The component type. This is a required field that tells Vector which
  # component to use. The value _must_ be `#{name}`.
  #
  # * required
  # * type: string
  # * must be: "vector"
  type = "vector"

  #
  # Buffer
  #

  [sinks.vector.buffer]
    # The maximum number of events allowed in the buffer.
    #
    # * optional
    # * default: 500
    # * type: uint
    # * unit: events
    # * relevant when type = "memory"
    max_events = 500

    # The maximum size of the buffer on the disk.
    #
    # * required
    # * type: uint
    # * unit: bytes
    # * required when type = "disk"
    max_size = 104900000

    # The buffer's type and storage mechanism.
    #
    # * optional
    # * default: "memory"
    # * type: string
    # * enum: "memory" or "disk"
    type = "memory"
    type = "disk"

    # The behavior when the buffer becomes full.
    #
    # * optional
    # * default: "block"
    # * type: string
    # * enum: "block" or "drop_newest"
    when_full = "block"
    when_full = "drop_newest"

  #
  # TLS
  #

  [sinks.vector.tls]
    # Absolute path to an additional CA certificate file, in DER or PEM format
    # (X.509), or an inline CA certificate in PEM format.
    #
    # * optional
    # * no default
    # * type: string
    ca_file = "/path/to/certificate_authority.crt"

    # Absolute path to a certificate file used to identify this connection, in DER
    # or PEM format (X.509) or PKCS#12, or an inline certificate in PEM format. If
    # this is set and is not a PKCS#12 archive, `key_file` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    crt_file = "/path/to/host_certificate.crt"

    # Enable TLS during connections to the remote.
    #
    # * optional
    # * default: false
    # * type: bool
    enabled = false
    enabled = true

    # Absolute path to a private key file used to identify this connection, in DER
    # or PEM format (PKCS#8), or an inline private key in PEM format. If this is
    # set, `crt_file` must also be set.
    #
    # * optional
    # * no default
    # * type: string
    key_file = "/path/to/host_certificate.key"

    # Pass phrase used to unlock the encrypted key file. This has no effect unless
    # `key_file` is set.
    #
    # * optional
    # * no default
    # * type: string
    key_pass = "${KEY_PASS_ENV_VAR}"
    key_pass = "PassWord1"

    # If `true` (the default), Vector will validate the TLS certificate of the
    # remote host.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_certificate = true
    verify_certificate = false

    # If `true` (the default), Vector will validate the configured remote host name
    # against the remote host's TLS certificate. Do NOT set this to `false` unless
    # you understand the risks of not verifying the remote hostname.
    #
    # * optional
    # * default: true
    # * type: bool
    verify_hostname = true
    verify_hostname = false
