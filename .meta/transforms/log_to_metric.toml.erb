[transforms.log_to_metric]
title = "Log to Metric"
allow_you_to_description = "convert logs into one or more metrics"
beta = false
common = true
function_category = "convert"
input_types = ["log"]
output_types = ["metric"]
requirements = {}

<%= render("_partials/fields/_component_options.toml", type: "transform", name: "log_to_metric") %>

[transforms.log_to_metric.options.metrics]
type = "[table]"
common = true
required = true
description = """\
A table of key/value pairs representing the keys to be added to the \
event.\
"""

[transforms.log_to_metric.options.metrics.children.type]
type = "string"
common = true
required = true
description = "The metric type."

[transforms.log_to_metric.options.metrics.children.type.enum]
counter = "A [counter metric type][docs.data-model.metric#counter]."
gauge = "A [gauge metric type][docs.data-model.metric#gauge]."
histogram = "A [distribution metric type][docs.data-model.metric#distribution]."
set = "A [set metric type][docs.data-model.metric#set]."

[transforms.log_to_metric.options.metrics.children.field]
type = "string"
common = true
examples = ["duration", "parent.child"]
field_path_notation = true
required = true
description = "The log field to use as the metric."

[transforms.log_to_metric.options.metrics.children.increment_by_value]
type = "bool"
default = false
relevant_when = {type = "counter"}
description = """\
If `true` the metric will be incremented by the `field` value. If `false` \
the metric will be incremented by 1 regardless of the `field` value.\
"""

[transforms.log_to_metric.options.metrics.children.name]
type = "string"
common = true
examples = ["duration_total"]
required = true
description = """\
The name of the metric. Defaults to `<field>_total` for `counter` and \
`<field>` for `gauge`.\
"""

[transforms.log_to_metric.options.metrics.children.tags]
type = "table"
common = true
description = "Key/value pairs representing [metric tags][docs.data-model.metric#tags]."

[transforms.log_to_metric.options.metrics.children.tags.children."`[tag-name]`"]
type = "string"
common = true
examples = [
  {"host" = "${HOSTNAME}"},
  {"region" = "us-east-1"},
  {"status" = "{{status}}"},
]
required = true
description = """\
Key/value pairs representing [metric tags][docs.data-model.metric#tags]. Environment \
variables and field interpolation is allowed.\
"""

[[transforms.log_to_metric.examples]]
label = "Histograms"
body = """\
This example demonstrates capturing timings in your logs.

```json title="log event"
{
  "host": "10.22.11.222",
  "message": "Sent 200 in 54.2ms",
  "status": 200,
  "time": 54.2,
}
```

You can convert the `time` field into a `distribution` metric:

```toml tite="vector.toml"
[transforms.log_to_metric]
  type = "log_to_metric"

  [[transforms.log_to_metric.metrics]]
    type = "histogram"
    field = "time"
    name = "time_ms" # optional
    tags.status = "{{status}}" # optional
    tags.host = "{{host}}" # optional
```

A [`metric` event][docs.data-model.metric] will be output with the following
structure:

```javascript title="metric event"
{
  "name": "time_ms",
  "kind": "incremental",
  "tags": {
    "status": "200",
    "host": "10.22.11.222"
  }
  "distribution": {
    "values": [54.2],
    "sample_rates": [1.0]
  }
}
```

This metric will then proceed down the pipeline, and depending on the sink,
will be aggregated in Vector (such is the case for the [`prometheus` \
sink][docs.sinks.prometheus]) or will be aggregated in the store itself.\
"""

[[transforms.log_to_metric.examples]]
label = "Counts"
body = """\
This example demonstrates counting HTTP status codes.

Given the following log line:

```json title="log event"
{
  "host": "10.22.11.222",
  "message": "Sent 200 in 54.2ms",
  "status": 200
}
```

You can count the number of responses by status code:

```toml title="vector.toml"
[transforms.log_to_metric]
  type = "log_to_metric"

  [[transforms.log_to_metric.metrics]]
    type = "counter"
    field = "status"
    name = "response_total" # optional
    tags.status = "{{status}}"
    tags.host = "{{host}}"
```

A [`metric` event][docs.data-model.metric] will be output with the following
structure:

```javascript title="metric event"
{
  "name": "response_total",
  "kind": "incremental",
  "tags": {
    "status": "200",
    "host": "10.22.11.222"
  }
  "counter": {
    "value": 1.0,
  }
}
```

This metric will then proceed down the pipeline, and depending on the sink,
will be aggregated in Vector (such is the case for the [`prometheus` \
sink][docs.sinks.prometheus]) or will be aggregated in the store itself.\
"""

[[transforms.log_to_metric.examples]]
label = "Sums"
body = """\
In this example we'll demonstrate computing a sum. The scenario we've chosen
is to compute the total of orders placed.

Given the following log line:

```json title="log event"
{
  "host": "10.22.11.222",
  "message": "Order placed for $122.20",
  "total": 122.2
}
```

You can reduce this log into a `counter` metric that increases by the
field's value:

```toml title="vector.toml"
[transforms.log_to_metric]
  type = "log_to_metric"

  [[transforms.log_to_metric.metrics]]
    type = "counter"
    field = "total"
    name = "order_total" # optional
    increment_by_value = true # optional
    tags.host = "{{host}}" # optional
```

A [`metric` event][docs.data-model.metric] will be output with the following
structure:

```javascript title="metric event"
{
  "name": "order_total",
  "kind": "incremental",
  "tags": {
    "status": "200",
    "host": "10.22.11.222"
  }
  "counter": {
    "value": 122.20,
  }
}
```

This metric will then proceed down the pipeline, and depending on the sink,
will be aggregated in Vector (such is the case for the [`prometheus` \
sink][docs.sinks.prometheus]) or will be aggregated in the store itself.\
"""

[[transforms.log_to_metric.examples]]
label = "Gauges"
body = """\
In this example we'll demonstrate creating a gauge that represents the current
CPU load verages.

Given the following log line:

```json title="log event"
{
  "host": "10.22.11.222",
  "message": "CPU activity sample",
  "1m_load_avg": 78.2,
  "5m_load_avg": 56.2,
  "15m_load_avg": 48.7
}
```

You can reduce this logs into multiple `gauge` metrics:

```toml title="vector.toml"
[transforms.log_to_metric]
  type = "log_to_metric"

  [[transforms.log_to_metric.metrics]]
    type = "gauge"
    field = "1m_load_avg"
    tags.host = "{{host}}" # optional

  [[transforms.log_to_metric.metrics]]
    type = "gauge"
    field = "5m_load_avg"
    tags.host = "{{host}}" # optional

  [[transforms.log_to_metric.metrics]]
    type = "gauge"
    field = "15m_load_avg"
    tags.host = "{{host}}" # optional
```

Multiple [`metric` events][docs.data-model.metric] will be output with the following
structure:

```javascript title="Metric event 1"
{
  "name": "1m_load_avg",
  "kind": "absolute",
  "tags": {
    "host": "10.22.11.222"
  },
  "gauge": {
    "value": 78.2
  }
}
```

```javascript title="Metric event 2"
{
  "name": "5m_load_avg",
  "kind": "absolute",
  "tags": {
    "host": "10.22.11.222"
  },
  "gauge": {
    "value": 56.2
  }
}
```

```javascript title="Metric event 3"
{
  "name": "15m_load_avg",
  "kind": "absolute",
  "tags": {
    "host": "10.22.11.222"
  },
  "gauge": {
    "value": 48.7
  }
}
```

This metric will then proceed down the pipeline, and depending on the sink,
will be aggregated in Vector (such is the case for the [`prometheus` \
sink][docs.sinks.prometheus]) or will be aggregated in the store itself.\
"""

[[transforms.log_to_metric.examples]]
label = "Set"
body = """\
In this example we'll demonstrate how to use sets. Sets are primarly a Statsd
concept that represent the number of unique values seens for a given metric.
The idea is that you pass the unique/high-cardinality value as the metric value
and the metric store will count the number of unique values seen.

For example, given the following log line:

```json title="log event"
{
  "host": "10.22.11.222",
  "message": "Sent 200 in 54.2ms",
  "remote_addr": "233.221.232.22"
}
```

You can count the number of unique `remote_addr` values by using a set:

```toml title="vector.toml"
[transforms.log_to_metric]
  type = "log_to_metric"

  [[transforms.log_to_metric.metrics]]
    type = "set"
    field = "remote_addr"
    tags.host = "{{host}}" # optional
```

A [`metric` event][docs.data-model.metric] will be output with the following
structure:

```javascript title="metric event"
{
  "name": "remote_addr",
  "kind": "incremental",
  "tags": {
    "host": "10.22.11.222"
  },
  "set": {
    "values": ["233.221.232.22"]
  }
}
```

This metric will then proceed down the pipeline, and depending on the sink,
will be aggregated in Vector (such is the case for the [`prometheus` \
sink][docs.sinks.prometheus]) or will be aggregated in the store itself.\
"""
