[sources.file]
title = "File"
noun = "a file"
beta = false
common = true
delivery_guarantee = "best_effort"
features = [
  "Tail one or more files.",
  "Automatically discover new files with glob patterns.",
  "Merge multi-line logs into one event.",
  "Checkpoint your position to ensure data is not lost between restarts.",
  "Enrich your logs with useful file and host-level context.",
]
function_category = "collect"
output_types = ["log"]
requirements.file_system = true
strategies = ["daemon", "sidecar"]
through_description = "one or more local files"

<%= render("_partials/fields/_component_options.toml", type: "source", name: "file") %>

[sources.file.options.data_dir]
type = "string"
examples = ["/var/lib/vector"]
description = """\
The directory used to persist file checkpoint positions. By default, the \
[global `data_dir` option][docs.global-options#data_dir] is used. Please make \
sure the Vector project has write permissions to this dir.\
"""

[sources.file.options.include]
type = "[string]"
common = true
examples = [["/var/log/nginx/*.log"]]
required = true
description = """\
Array of file patterns to include. [Globbing](#globbing) is supported.\
"""

[sources.file.options.exclude]
type = "[string]"
examples = [["/var/log/nginx/*.[0-9]*.log"]]
description = """\
Array of file patterns to exclude. [Globbing](#globbing) is supported.\
*Takes precedence over the [`include` option](#include).*\
"""

[sources.file.options.file_key]
type = "string"
category = "Context"
default = "file"
description = """\
The key name added to each event with the full path of the file.\
"""

[sources.file.options.glob_minimum_cooldown]
type = "uint"
default = 1000
unit = "milliseconds"
description = """\
Delay between file discovery calls. This controls the interval at which \
Vector searches for files.\
"""

[sources.file.options.host_key]
type = "string"
category = "Context"
default = "host"
description = """\
The key name added to each event representing the current host. This can also \
be globally set via the \
[global `host_key` option][docs.reference.global-options#host_key].\
"""

[sources.file.options.ignore_older]
type = "uint"
common = true
examples = [86400]
unit = "seconds"
description = """\
Ignore files with a data modification date that does not exceed this age.\
"""

[sources.file.options.max_line_bytes]
type = "uint"
unit = "bytes"
default = 102400
description = """\
The maximum number of a bytes a line can contain before being \
discarded. This protects against malformed lines or tailing incorrect \
files.\
"""

[sources.file.options.start_at_beginning]
type = "bool"
common = true
default = false
description = """\
For files with a stored checkpoint at startup, setting this option \
to `true` will tell Vector to read from the beginning of the file instead \
of the stored checkpoint. \
"""

[sources.file.options.fingerprinting]
type = "table"
description = """\
Configuration for how the file source should identify files.\
"""

[sources.file.options.fingerprinting.children.strategy]
type = "string"
default = "checksum"
sort = 1
description = """\
The strategy used to uniquely identify files. This is important for \
[checkpointing](#checkpointing) when file rotation is used.\
"""

[sources.file.options.fingerprinting.children.strategy.enum]
checksum = "Read `fingerprint_bytes` bytes from the head of the file to uniquely identify files via a checksum."
device_and_inode = "Uses the [device and inode][urls.inode] to unique identify files."

[sources.file.options.fingerprinting.children.fingerprint_bytes]
type = "uint"
default = 256
unit = "bytes"
relevant_when = {strategy = "checksum"}
description = """\
The number of bytes read off the head of the file to generate a unique \
fingerprint.\
"""

[sources.file.options.fingerprinting.children.ignored_header_bytes]
type = "uint"
default = 0
unit = "bytes"
relevant_when = {strategy = "checksum"}
description = """\
The number of bytes to skip ahead (or ignore) when generating a unique \
fingerprint. This is helpful if all files share a common header.\
"""

[sources.file.options.max_read_bytes]
type = "uint"
category = "Priority"
default = 2048
unit = "bytes"
description = """\
An approximate limit on the amount of data read from a single file at a given \
time.\
"""

[sources.file.options.multiline]
type = "table"
category = "Multiline"
description = """\
Multiline parsing configuration (per file).
If not speicified, multiline parsing is disabled.\
"""

[sources.file.options.multiline.children.start_pattern]
type = "string"
category = "Multiline"
examples = ["^[^\\s]", "\\\\$", "^(INFO|ERROR) ", "[^;]$"]
required = true
sort = 1
description = """\
Start regex pattern to look for as a beginning of the message.\
"""

[sources.file.options.multiline.children.condition_pattern]
type = "string"
category = "Multiline"
examples = ["^[\\s]+", "\\\\$", "^(INFO|ERROR) ", ";$"]
required = true
sort = 3
description = """\
Condition regex pattern to look for. Exact behavior is configured via `mode`.\
"""

[sources.file.options.multiline.children.mode]
type = "string"
category = "Multiline"
required = true
sort = 2
description = """\
Mode of operation, specifies how the `condition_pattern` is interpreted.\
"""

[sources.file.options.multiline.children.mode.enum]
continue_through = """\
All consecutive lines matching this pattern are included in the group. \
The first line (the line that matched the start pattern) does not need \
to match the `ContinueThrough` pattern. \
This is useful in cases such as a Java stack trace, where some indicator \
in the line (such as leading whitespace) indicates that it is an \
extension of the preceeding line.\
"""
continue_past = """\
All consecutive lines matching this pattern, plus one additional line, \
are included in the group. \
This is useful in cases where a log message ends with a continuation \
marker, such as a backslash, indicating that the following line is part \
of the same message.\
"""
halt_before = """\
All consecutive lines not matching this pattern are included in the \
group. \
This is useful where a log line contains a marker indicating that it \
begins a new message.\
"""
halt_with = """\
All consecutive lines, up to and including the first line matching this \
pattern, are included in the group. \
This is useful where a log line ends with a termination marker, such as \
a semicolon.\
"""

[sources.file.options.multiline.children.timeout_ms]
type = "uint"
category = "Multiline"
examples = [1000, 600000]
unit = "milliseconds"
common = true
required = true
sort = 4
description = """\
The maximum time to wait for the continuation. Once this timeout is \
reached, the buffered message is guaraneed to be flushed, even if \
incomplete.\
"""

[sources.file.options.oldest_first]
type = "bool"
category = "Priority"
common = true
default = false
description = """\
Instead of balancing read capacity fairly across all watched files, prioritize \
draining the oldest files before moving on to read data from younger files.\
"""

[sources.file.options.remove_after]
type = "uint"
unit = "seconds"
common = false
examples = [0, 5, 60]
description = """\
Timeout from reaching `eof` after which file will be removed from filesystem, \
unless new data is written in the meantime. \
If not specified, files will not be removed.\
"""
warnings = [{visibility_level = "option", text = "Vector's process must have permission to delete files."}]

[sources.file.fields.log.fields.file]
type = "string"
examples = ["/var/log/nginx.log"]
required = true
description = """\
The _full_ path of the file tha the log originated from. This can be renamed \
via the `file_key` option.\
"""

[sources.file.fields.log.fields.host]
type = "string"
examples = ["my.host.com"]
required = true
description = """\
The current hostname, equivalent to the `gethostname` command. This can be \
renamed via the `host_key` option.\
"""

[sources.file.fields.log.fields.message]
type = "string"
examples = ["Started GET / for 127.0.0.1 at 2012-03-10 14:28:14 +0100"]
required = true
description = """\
The raw log message, unaltered. This can be renamed via the \
[global `message_key` option][docs.reference.global-options#message_key].\
"""

[sources.file.fields.log.fields.timestamp]
type = "timestamp"
examples = ["2019-11-01T21:15:47.443232Z"]
required = true
description = """\
The exact time the event was ingested. This can be renamed via the \
[global `timestamp_key` option][docs.reference.global-options#timestamp_key].\
"""
